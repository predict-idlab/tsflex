<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>tsflex.features.segmenter.strided_rolling API documentation</title>
<meta name="description" content="Withholds a (rather) fast implementation of an **index-based** strided rolling window â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/foundation.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em;padding-left:1em;padding-right:1em}button{display:none}#sidebar{padding:3px;max-width:20em;overflow:hidden;min-width:19.8em}#sidebar > *:last-child{margin-bottom:1cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;border-top:1px solid #ddd;text-align:right}#footer p{}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f1f3f9;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:0.5em;padding:0px}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;max_width:100%;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.info{background:#edfcf4}.admonition.note,.admonition.important{background:#ebf3ff}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#edfcf4}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#ffddcc}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:850px){.sidebar_container{display:flex;transition:0.75s ease}.sidebar_small{width:0;margin:0;padding:0}.hide_content{display:none}button{display:initial;float:left;position:sticky;border:none;height:5ch;width:5ch;border-radius:50%;box-shadow:0px 1px 4px 1px rgba(0,0,0,.2);top:5%;left:100%;transform:translateX(-50%);cursor:pointer}#sidebar{width:25%;height:100vh;overflow:auto;position:sticky;top:0;transition:0.75s ease}#index_button_img{opacity:0.65}#content{max-width:105ch;padding:2em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1em;padding-right:0.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-212611910-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-212611910-1');
</script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://media.discordapp.net/attachments/372491075153166338/852906324417445908/icon.png">
</head>
<body>
<main>
<article id="content">
<button id="index_button_button"><img id="index_button_img"
src="https://image.flaticon.com/icons/png/512/56/56763.png"
alt="" width="33" height="25"></button>
<header>
<h1 class="title">Module <code>tsflex.features.segmenter.strided_rolling</code></h1>
</header>
<section id="section-intro">
<p>Withholds a (rather) fast implementation of an <strong>index-based</strong> strided rolling window.</p>
<div class="admonition todo">
<p class="admonition-title">TODO</p>
<p>Look into the implementation of a new func-input-data-type that is a
Tuple[index, values]. This should be multitudes faster than using the
series-datatype and the user can still leverage the index-awareness of the values.</p>
</div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Withholds a (rather) fast implementation of an **index-based** strided rolling window.

.. TODO::

    Look into the implementation of a new func-input-data-type that is a
    Tuple[index, values]. This should be multitudes faster than using the
    series-datatype and the user can still leverage the index-awareness of the values.

&#34;&#34;&#34;

from __future__ import annotations

__author__ = &#34;Jonas Van Der Donckt, Jeroen Van Der Donckt&#34;

import time
import warnings
from abc import ABC, abstractmethod
from collections import namedtuple
from typing import List, Optional, Tuple, TypeVar, Union

import numpy as np
import pandas as pd

from ...utils.attribute_parsing import AttributeParser, DataType
from ...utils.data import SUPPORTED_STROLL_TYPES, to_list, to_series_list, to_tuple
from ...utils.time import timedelta_to_str
from ..function_wrapper import FuncWrapper, _get_name
from ..logger import logger
from ..utils import _check_start_end_array, _determine_bounds

# Declare a type variable
T = TypeVar(&#34;T&#34;)


class StridedRolling(ABC):
    &#34;&#34;&#34;Custom time-based sliding window with stride.

    Parameters
    ----------
    data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]
        ``pd.Series`` or ``pd.DataFrame`` to slide over, the index must be either
        numeric or a ``pd.DatetimeIndex``.
    window : Union[float, pd.Timedelta]
        Either an int, float, or ``pd.Timedelta``, representing the sliding window size
        in terms of the index (in case of a int or float) or the sliding window duration
        (in case of ``pd.Timedelta``).
    strides : Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]], optional
        Either a list of int, float, or ``pd.Timedelta``, representing the stride sizes
        in terms of the index (in case of a int or float) or the stride duration (in
        case of ``pd.Timedelta``). By default None.
    segment_start_idxs: np.ndarray, optional
        The start indices for the segmented windows. If not provided, the start indices
        will be computed from the data using the passed ``strides`` or by using the
        ``segment_end_idxs`` (if not none) + ``window``. By default None.
    segment_end_idxs: np.ndarray, optional
        The end indices for the segmented windows. If not provided, the end indices will
        be computed from either (1) the data using the passed ``window`` + ``strides``
        or (2) the ``segment_start_idxs`` + ``window``, By default None.
        .. Note::
            When you pass arrays to both ``segment_start_idxs`` and
            ``segment_end_idxs``, the corresponding index-values of these arrays will be
            used as segment-ranges. As a result, the following properties must be met:\n
              - both arrays should have equal length
              - all values in ``segment_start_idxs`` should be &lt;= ``segment_end_idxs``
    start_idx: Union[float, pd.Timestamp], optional
        The start-index which will be used for each series passed to `data`. This is
        especially useful if multiple ``StridedRolling`` instances are created and the
        user want to ensure same (start-)indexes for each of them.
    end_idx: Union[float, pd.Timestamp], optional
        The end-index which will be used as sliding end-limit for each series passed to
        `data`.
    func_data_type: Union[np.array, pd.Series], optional
        The data type of the stroll (either np.array or pd.Series), by default np.array.
        &lt;br&gt;
        .. Note::
            Make sure to only set this argument to pd.Series when this is really
            required, since pd.Series strided-rolling is significantly less efficient.
            For a np.array it is possible to create very efficient views, but there is
            no such thing as a pd.Series view. Thus, for each stroll, a new series is
            created, inducing a lot of non-feature calculation of overhead.
    window_idx : str, optional
        The window&#39;s index position which will be used as index for the
        feature_window aggregation. Must be either of: `[&#34;begin&#34;, &#34;middle&#34;, &#34;end&#34;]`, by
        default &#34;end&#34;.
    include_final_window: bool, optional
        Whether the final (possibly incomplete) window should be included in the
        strided-window segmentation, by default False.

        .. Note::
            The remarks below apply when ``include_final_window`` is set to True.
            The user should be aware that the last window *might* be incomplete, i.e.;

            - when equally sampled, the last window *might* be smaller than the
              the other windows.
            - when not equally sampled, the last window *might* not include all the
                data points (as the begin-time + window-size comes after the last data
                point).

            Note, that when equally sampled, the last window *will* be a full window
            when:

            - the stride is the sampling rate of the data (or stride = 1 for
              sample-based configurations).&lt;br&gt;
              **Remark**: that when `include_final_window` is set to False, the last
              window (which is a full) window will not be included!
            - *(len * sampling_rate - window_size) % stride = 0*. Remark that the above
              case is a base case of this.
    approve_sparsity: bool, optional
        Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
        irregularly sampled data), by default False.
        If False and sparsity is observed, a warning is raised.

    Notes
    -----
    * This instance withholds a **read-only**-view of the data its values.

    &#34;&#34;&#34;

    # Class variables which are used by subclasses
    win_str_type: DataType
    reset_series_index_b4_segmenting: bool = False
    OUTSIDE_DATA_BOUNDS_WARNING: str = (
        &#34;Some segment indexes are outside the range of the data its index.&#34;
    )

    # Create the named tuple
    _NumpySeriesContainer = namedtuple(
        &#34;SeriesContainer&#34;, [&#34;name&#34;, &#34;values&#34;, &#34;start_indexes&#34;, &#34;end_indexes&#34;]
    )

    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: T,
        strides: Optional[Union[T, List[T]]] = None,
        segment_start_idxs: Optional[np.ndarray] = None,
        segment_end_idxs: Optional[np.ndarray] = None,
        start_idx: Optional[T] = None,
        end_idx: Optional[T] = None,
        func_data_type: Optional[Union[np.array, pd.Series]] = np.array,
        window_idx: Optional[str] = &#34;end&#34;,
        include_final_window: bool = False,
        approve_sparsity: Optional[bool] = False,
    ):
        if strides is not None:
            strides = to_list(strides)

        # Check the passed segment indices
        if segment_start_idxs is not None and segment_end_idxs is not None:
            _check_start_end_array(segment_start_idxs, segment_end_idxs)

        if window is not None:
            assert AttributeParser.check_expected_type(
                [window] + ([] if strides is None else strides), self.win_str_type
            )

        self.window = window
        self.strides = strides

        self.window_idx = window_idx
        self.include_final_window = include_final_window
        self.approve_sparsity = approve_sparsity

        assert func_data_type in SUPPORTED_STROLL_TYPES
        self.data_type = func_data_type

        # 0. Standardize the input
        series_list: List[pd.Series] = to_series_list(data)
        self.series_dtype = AttributeParser.determine_type(series_list)
        self.series_key: Tuple[str, ...] = tuple([str(s.name) for s in series_list])

        # 1. Determine the start index
        self.start, self.end = start_idx, end_idx
        if self.start is None or self.end is None:
            # We always pass start_idx and end_idx from the FeatureCollection.calculate
            # Hence, this code is only useful for testing purposes
            start, end = _determine_bounds(&#34;inner&#34;, series_list)

            # update self.start &amp; self.end if it was not passed
            self.start = start if self.start is None else self.start
            self.end = end if self.end is None else self.end

        # Especially useful when the index dtype differs from the win-stride-dtype
        # e.g. -&gt; performing a int-based stroll on time-indexed data
        # Note: this is very niche and thus requires advanced knowledge
        # TODO: this code can be omitted if we remove TimeIndexSampleStridedRolling
        self._update_start_end_indices_to_stroll_type(series_list)

        # 2. Construct the index ranges
        # Either use the passed segment indices or compute the start or end times of the
        # segments. The segment indices have precedence over the stride (and window) for
        # index computation.
        if segment_start_idxs is not None or segment_end_idxs is not None:
            self.strides = None
            if segment_start_idxs is not None and segment_end_idxs is not None:
                # When both the start and end points are passed, the window does not
                # matter.
                self.window = None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = self._parse_segment_idxs(segment_end_idxs)
            elif segment_start_idxs is not None:  # segment_end_idxs is None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = np_start_times + self._get_np_value(self.window)
            else:  # segment_end_idxs is not None and segment_start_idxs is None
                np_end_times = self._parse_segment_idxs(segment_end_idxs)
                np_start_times = np_end_times - self._get_np_value(self.window)
        else:
            np_start_times = self._construct_start_idxs()
            np_end_times = np_start_times + self._get_np_value(self.window)

        # Check the numpy start and end indices
        _check_start_end_array(np_start_times, np_end_times)

        # 3. Create a new-index which will be used for DataFrame reconstruction
        # Note: the index-name of the first passed series will be re-used as index-name
        self.index = self._get_output_index(
            np_start_times, np_end_times, name=series_list[0].index.name
        )

        # 4. Store the series containers
        self.series_containers = self._construct_series_containers(
            series_list, np_start_times, np_end_times
        )

        # 5. Check the sparsity assumption
        if not self.approve_sparsity and len(self.index):
            for container in self.series_containers:
                # Warn when min != max
                if np.ptp(container.end_indexes - container.start_indexes) != 0:
                    warnings.warn(
                        f&#34;There are gaps in the sequence of the {container.name}&#34;
                        f&#34;-series!&#34;,
                        RuntimeWarning,
                    )

    def _calc_nb_segments_for_stride(self, stride) -&gt; int:
        &#34;&#34;&#34;Calculate the number of output items (segments) for a given single stride.&#34;&#34;&#34;
        nb_feats = max((self.end - self.start - self.window) // stride + 1, 0)
        # Add 1 if there is still some data after (including) the last window its
        # start index - this is only added when `include_last_window` is True.
        nb_feats += self.include_final_window * (
            self.start + stride * nb_feats &lt;= self.end
        )
        return nb_feats

    def _get_np_start_idx_for_stride(self, stride: T) -&gt; np.ndarray:
        &#34;&#34;&#34;Compute the start index for the given single stride.&#34;&#34;&#34;
        # ---------- Efficient numpy code -------
        np_start = self._get_np_value(self.start)
        np_stride = self._get_np_value(stride)
        # Compute the start times (these remain the same for each series)
        return np.arange(
            start=np_start,
            stop=np_start + self._calc_nb_segments_for_stride(stride) * np_stride,
            step=np_stride,
        )

    def _construct_start_idxs(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Construct the start indices of the segments (for all stride values).

        To realize this, we compute the start idxs for each stride and then merge them
        together (without duplicates) in a sorted array.
        &#34;&#34;&#34;
        start_idxs = []
        for stride in self.strides:
            start_idxs += [self._get_np_start_idx_for_stride(stride)]
        # note - np.unique also sorts the array
        return np.unique(np.concatenate(start_idxs))

    def _get_output_index(
        self, start_idxs: np.ndarray, end_idxs: Union[np.ndarray, None], name: str
    ) -&gt; pd.Index:
        &#34;&#34;&#34;Construct the output index.&#34;&#34;&#34;
        if self.window_idx == &#34;end&#34;:
            return pd.Index(end_idxs, name=name)
        elif self.window_idx == &#34;middle&#34;:
            return pd.Index(
                start_idxs + ((end_idxs - start_idxs) / 2),
                name=name,
            )
        elif self.window_idx == &#34;begin&#34;:
            return pd.Index(start_idxs, name=name)
        else:
            raise ValueError(
                f&#34;window index {self.window_idx} must be either of: &#34;
                &#34;[&#39;end&#39;, &#39;middle&#39;, &#39;begin&#39;]&#34;
            )

    def _construct_series_containers(
        self, series_list, np_start_times, np_end_times
    ) -&gt; List[StridedRolling._NumpySeriesContainer]:
        series_containers: List[StridedRolling._NumpySeriesContainer] = []
        for series in series_list:
            if not self.reset_series_index_b4_segmenting:
                np_idx_times = series.index.values
            else:
                np_idx_times = np.arange(len(series))
                # note: using pd.RangeIndex instead of arange gives the same performance

            series_name = series.name
            if self.data_type is np.array:
                # create a non-writeable view of the series
                series = series.values
                series.flags.writeable = False
            elif self.data_type is pd.Series:
                series.values.flags.writeable = False
                series.index.values.flags.writeable = False
            else:
                raise ValueError(&#34;unsupported datatype&#34;)

            series_containers.append(
                StridedRolling._NumpySeriesContainer(
                    name=series_name,
                    values=series,
                    # the slicing will be performed on [ t_start, t_end [
                    # TODO: this can maybe be optimized -&gt; further look into this
                    # np_idx_times, np_start_times, &amp; np_end_times are all sorted!
                    # as we assume &amp; check that the time index is monotonically
                    # increasing &amp; the latter 2 are created using `np.arange()`
                    start_indexes=np.searchsorted(np_idx_times, np_start_times, &#34;left&#34;),
                    end_indexes=np.searchsorted(np_idx_times, np_end_times, &#34;left&#34;),
                )
            )
        return series_containers

    def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Apply a function to the segmented series.

        Parameters
        ----------
        func : FuncWrapper
            The Callable wrapped function which will be applied.

        Returns
        -------
        pd.DataFrame
            The merged output of the function applied to every column in a
            new DataFrame. The DataFrame&#39;s column-names have the format:
                `&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;`.

        Raises
        ------
        ValueError
            If the passed ``func`` tries to adjust the data its read-only view.

        Notes
        -----
        * If ``func`` is only a callable argument, with no additional logic, this
          will only work for a one-to-one mapping, i.e., no multiple feature-output
          columns are supported for this case!&lt;br&gt;
        * If you want to calculate one-to-many, ``func`` should be
          a ``FuncWrapper`` instance and explicitly use
          the ``output_names`` attributes of its constructor.

        &#34;&#34;&#34;
        feat_names = func.output_names

        t_start = time.perf_counter()

        # --- Future work ---
        # would be nice if we could optimize this double for loop with something
        # more vectorized
        #
        # As for now we use a map to apply the function (as this evaluates its
        # expression only once, whereas a list comprehension evaluates its expression
        # every time).
        # See more why: https://stackoverflow.com/a/59838723
        out: np.array
        if func.vectorized:
            # Vectorized function execution

            ## IMPL 1
            ## Results in a high memory peak as a new np.array is created (and thus no
            ## view is being used)
            # out = np.asarray(
            #         func(
            #             *[
            #                 np.array([
            #                     sc.values[sc.start_indexes[idx]: sc.end_indexes[idx]]
            #                     for idx in range(len(self.index))
            #                 ])
            #                 for sc in self.series_containers
            #             ],
            #         )
            #     )

            ## IMPL 2
            ## Is a good implementation (equivalent to the one below), will also fail in
            ## the same cases, but it does not perform clear assertions (with their
            ## accompanied clear messages).
            # out = np.asarray(
            #     func(
            #         *[
            #             _sliding_strided_window_1d(sc.values, self.window, self.stride)
            #             for sc in self.series_containers
            #         ],
            #     )
            # )

            views = []
            for sc in self.series_containers:
                if len(sc.start_indexes) == 0:
                    # There are no feature windows  -&gt; return empty array (see below)
                    views = []
                    break
                elif len(sc.start_indexes) == 1:
                    # There is only 1 feature window (bc no steps in the sliding window)
                    views.append(
                        np.expand_dims(
                            sc.values[sc.start_indexes[0] : sc.end_indexes[0]],
                            axis=0,
                        )
                    )
                else:
                    # There are &gt;1 feature windows (bc &gt;=1 steps in the sliding window)
                    windows = sc.end_indexes - sc.start_indexes
                    strides = sc.start_indexes[1:] - sc.start_indexes[:-1]
                    assert np.all(windows == windows[0]), (
                        &#34;Vectorized functions require same number of samples in each &#34;
                        + &#34;segmented window!&#34;
                    )
                    assert np.all(
                        strides == strides[0]
                    ), &#34;Vectorized functions require same number of samples as stride!&#34;
                    views.append(
                        _sliding_strided_window_1d(
                            sc.values[sc.start_indexes[0] :],
                            windows[0],
                            strides[0],
                            len(self.index),
                        )
                    )

            # Assign empty array as output when there is no view to apply the vectorized
            # function on (this is the case when there is at least for one series no
            # feature windows)
            out = func(*views) if len(views) &gt;= 1 else np.array([])

            out_type = type(out)
            out = np.asarray(out)
            # When multiple outputs are returned (= tuple) they should be transposed
            # when combining into an array
            out = out.T if out_type is tuple else out

        else:
            # Sequential function execution (default)
            out = np.array(
                list(
                    map(
                        func,
                        *[
                            [
                                sc.values[sc.start_indexes[idx] : sc.end_indexes[idx]]
                                for idx in range(len(self.index))
                            ]
                            for sc in self.series_containers
                        ],
                    )
                )
            )

        # Check if the function output is valid.
        # This assertion will be raised when e.g. np.max is applied vectorized without
        # specifying axis=1.
        assert out.ndim &gt; 0, &#34;Vectorized function returned only 1 (non-array) value!&#34;

        # Aggregate function output in a dictionary
        feat_out = {}
        if out.ndim == 1 and not len(out):
            # When there are no features calculated (due to no feature windows)
            assert not len(self.index)
            for f_name in feat_names:
                # Will be discarded (bc no index)
                feat_out[self._create_feat_col_name(f_name)] = None
        elif out.ndim == 1 or (out.ndim == 2 and out.shape[1] == 1):
            assert len(feat_names) == 1, f&#34;Func {func} returned more than 1 output!&#34;
            feat_out[self._create_feat_col_name(feat_names[0])] = out.flatten()
        else:
            assert out.ndim == 2 and out.shape[1] &gt; 1
            assert (
                len(feat_names) == out.shape[1]
            ), f&#34;Func {func} returned incorrect number of outputs ({out.shape[1]})!&#34;
            for col_idx in range(out.shape[1]):
                feat_out[self._create_feat_col_name(feat_names[col_idx])] = out[
                    :, col_idx
                ]

        elapsed = time.perf_counter() - t_start
        log_strides = (
            &#34;manual&#34; if self.strides is None else tuple(map(str, self.strides))
        )
        log_window = &#34;manual&#34; if self.window is None else self.window
        logger.info(
            f&#34;Finished function [{_get_name(func.func)}] on &#34;
            f&#34;{[self.series_key]} with window-stride [{log_window}, {log_strides}] &#34;
            f&#34;with output {list(feat_out.keys())} in [{elapsed} seconds]!&#34;
        )

        return pd.DataFrame(index=self.index, data=feat_out)

    # --------------------------------- STATIC METHODS ---------------------------------
    @staticmethod
    def _get_np_value(val):
        # Convert everything to int64
        if isinstance(val, pd.Timestamp):
            return val.to_datetime64()
        elif isinstance(val, pd.Timedelta):
            return val.to_timedelta64()
        else:
            return val

    @staticmethod
    def construct_output_index(
        series_keys: Union[str, Tuple[str, ...]], feat_name: str, win_str: str
    ) -&gt; str:
        series_keys = to_tuple(series_keys)
        return f&#34;{&#39;|&#39;.join(series_keys)}__{feat_name}__w={win_str}&#34;

    # ----------------------------- OVERRIDE THESE METHODS -----------------------------
    @abstractmethod
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        # NOTE: This method will only be implemented (with code != pass) in the
        # TimeIndexSampleStridedRolling
        raise NotImplementedError

    @abstractmethod
    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Check the segment indexes array to lie between self.start and self.end and
        convert it to the correct dtype (if necessary).&#34;&#34;&#34;
        raise NotImplementedError

    @abstractmethod
    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        raise NotImplementedError


class SequenceStridedRolling(StridedRolling):
    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: float,
        strides: Optional[Union[float, List[float]]] = None,
        *args,
        **kwargs,
    ):
        # Set the data type &amp; call the super constructor
        self.win_str_type = DataType.SEQUENCE
        super().__init__(data, window, strides, *args, **kwargs)

    # ------------------------------- Overridden methods -------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        pass

    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        if any((segment_idxs &lt; self.start) | (segment_idxs &gt; self.end)):
            warnings.warn(self.OUTSIDE_DATA_BOUNDS_WARNING, RuntimeWarning)
        return segment_idxs

    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        if self.window is not None:
            win_str = str(self.window)
        else:
            win_str = &#34;manual&#34;
        return self.construct_output_index(
            series_keys=self.series_key, feat_name=feat_name, win_str=win_str
        )


class TimeStridedRolling(StridedRolling):
    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: pd.Timedelta,
        strides: Optional[Union[pd.Timedelta, List[pd.Timedelta]]] = None,
        *args,
        **kwargs,
    ):
        # Check that each series / dataframe has the same tz
        data = to_series_list(data)
        tz_index = data[0].index.tz
        for data_entry in to_series_list(data)[1:]:
            assert (
                data_entry.index.tz == tz_index
            ), &#34;strided rolling input data must all have same timezone&#34;
        self._tz_index = tz_index
        # Set the data type &amp; call the super constructor
        self.win_str_type = DataType.TIME
        super().__init__(data, window, strides, *args, **kwargs)

    # -------------------------------- Extended methods --------------------------------
    def _get_output_index(
        self, start_idxs: np.ndarray, end_idxs: np.ndarray, name: str
    ) -&gt; pd.Index:
        assert start_idxs.dtype.type == np.datetime64
        assert end_idxs.dtype.type == np.datetime64
        start_idxs = pd.to_datetime(start_idxs, utc=True).tz_convert(self._tz_index)
        end_idxs = pd.to_datetime(end_idxs, utc=True).tz_convert(self._tz_index)
        return super()._get_output_index(start_idxs, end_idxs, name)

    # ------------------------------- Overridden methods -------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        pass

    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        segment_idxs = segment_idxs.astype(&#34;datetime64&#34;)
        start_, end_ = self.start, self.end
        if start_.tz is not None:
            # Convert to UTC (allowing comparison with the segment_idxs)
            assert end_.tz is not None
            start_ = start_.tz_convert(None)
            end_ = end_.tz_convert(None)
        if any((segment_idxs &lt; start_) | (segment_idxs &gt; end_)):
            warnings.warn(self.OUTSIDE_DATA_BOUNDS_WARNING, RuntimeWarning)
        return segment_idxs

    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        # Convert win to time-string if available :)
        if self.window is not None:
            win_str = timedelta_to_str(self.window)
        else:
            win_str = &#34;manual&#34;
        return self.construct_output_index(
            series_keys=self.series_key, feat_name=feat_name, win_str=win_str
        )


class TimeIndexSampleStridedRolling(SequenceStridedRolling):
    def __init__(
        self,
        # TODO -&gt; update arguments
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: int,
        strides: Optional[Union[int, List[int]]] = None,
        segment_start_idxs: Optional[np.ndarray] = None,
        segment_end_idxs: Optional[np.ndarray] = None,
        *args,
        **kwargs,
    ):
        &#34;&#34;&#34;
        .. Warning::
            When `data` consists of multiple independently sampled series
            (e.g. feature functions which take multiple series as input),
            The time-**index of each series**: \n
            - must _roughly_ **share** the same **sample frequency**.
            - will be first time-aligned before transitioning to sample-segmentation by
              using the inner bounds

        .. Note::
            `TimeIndexSampleStridedRolling` **does not support** the
            ``segment_start_idxs`` and ``segment_end_idxs`` arguments. Setting these
            will raise a NotImplementedError.

        &#34;&#34;&#34;
        if segment_start_idxs is not None or segment_end_idxs is not None:
            raise NotImplementedError(
                &#34;TimeIndexSampleStridedRolling is not implemented to support passing&#34;
                + &#34;segment_start_idxs or segment_end_idxs&#34;
            )

        # We want to reset the index as its type differs from the passed win-stride
        # configs
        self.reset_series_index_b4_segmenting = True

        series_list = to_series_list(data)
        if isinstance(data, list) and len(data) &gt; 1:
            # Slice data into its inner range so that the start position
            # is aligned (when we will use sample-based methodologies)
            start, end = _determine_bounds(&#34;inner&#34;, series_list)
            series_list = [s[start:end] for s in series_list]
            kwargs.update({&#34;start_idx&#34;: start, &#34;end_idx&#34;: end})

        # We retain the first series list to stitch back the output index
        self._series_index = series_list[0].index

        # pass the sliced series list instead of data
        super().__init__(series_list, window, strides, *args, **kwargs)

        assert self.series_dtype == DataType.TIME

        # we want to assure that the window-stride arguments are integers (samples)
        assert all(isinstance(p, int) for p in [self.window] + self.strides)

    def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
        # Apply the function and stitch back the time-index
        df = super().apply_func(func)
        df.index = self._series_index[df.index]
        return df

    # ---------------------------- Overridden methods ------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        # update the start and end times to the sequence datatype
        self.start, self.end = np.searchsorted(
            series_list[0].index.values,
            [self.start.to_datetime64(), self.end.to_datetime64()],
            &#34;left&#34;,
        )


def _sliding_strided_window_1d(
    data: np.ndarray, window: int, step: int, nb_segments: int
):
    &#34;&#34;&#34;View based sliding strided-window for 1-dimensional data.

    Parameters
    ----------
    data: np.array
        The 1-dimensional series to slide over.
    window: int
        The window size, in number of samples.
    step: int
        The step size (i.e., the stride), in number of samples.
    nb_segments: int
        The number of sliding window steps, this is equal to the number of feature
        windows.

    Returns
    -------
    nd.array
        A view of the sliding strided window of the data.

    &#34;&#34;&#34;
    # window and step in samples
    assert data.ndim == 1, &#34;data must be 1 dimensional&#34;
    assert isinstance(window, (int, np.integer)), &#34;window must be an integer&#34;
    assert isinstance(step, (int, np.integer)), &#34;step must be an integer&#34;

    assert (step &gt;= 1) &amp; (window &lt; len(data))

    shape = [
        nb_segments,
        window,
    ]

    strides = [
        data.strides[0] * step,
        data.strides[0],
    ]

    return np.lib.stride_tricks.as_strided(
        data, shape=shape, strides=strides  # , writeable=False
    )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling"><code class="flex name class">
<span>class <span class="ident">StridedRolling</span></span>
<span>(</span><span>data, window, strides=None, segment_start_idxs=None, segment_end_idxs=None, start_idx=None, end_idx=None, func_data_type=&lt;built-in function array&gt;, window_idx='end', include_final_window=False, approve_sparsity=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StridedRolling(ABC):
    &#34;&#34;&#34;Custom time-based sliding window with stride.

    Parameters
    ----------
    data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]
        ``pd.Series`` or ``pd.DataFrame`` to slide over, the index must be either
        numeric or a ``pd.DatetimeIndex``.
    window : Union[float, pd.Timedelta]
        Either an int, float, or ``pd.Timedelta``, representing the sliding window size
        in terms of the index (in case of a int or float) or the sliding window duration
        (in case of ``pd.Timedelta``).
    strides : Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]], optional
        Either a list of int, float, or ``pd.Timedelta``, representing the stride sizes
        in terms of the index (in case of a int or float) or the stride duration (in
        case of ``pd.Timedelta``). By default None.
    segment_start_idxs: np.ndarray, optional
        The start indices for the segmented windows. If not provided, the start indices
        will be computed from the data using the passed ``strides`` or by using the
        ``segment_end_idxs`` (if not none) + ``window``. By default None.
    segment_end_idxs: np.ndarray, optional
        The end indices for the segmented windows. If not provided, the end indices will
        be computed from either (1) the data using the passed ``window`` + ``strides``
        or (2) the ``segment_start_idxs`` + ``window``, By default None.
        .. Note::
            When you pass arrays to both ``segment_start_idxs`` and
            ``segment_end_idxs``, the corresponding index-values of these arrays will be
            used as segment-ranges. As a result, the following properties must be met:\n
              - both arrays should have equal length
              - all values in ``segment_start_idxs`` should be &lt;= ``segment_end_idxs``
    start_idx: Union[float, pd.Timestamp], optional
        The start-index which will be used for each series passed to `data`. This is
        especially useful if multiple ``StridedRolling`` instances are created and the
        user want to ensure same (start-)indexes for each of them.
    end_idx: Union[float, pd.Timestamp], optional
        The end-index which will be used as sliding end-limit for each series passed to
        `data`.
    func_data_type: Union[np.array, pd.Series], optional
        The data type of the stroll (either np.array or pd.Series), by default np.array.
        &lt;br&gt;
        .. Note::
            Make sure to only set this argument to pd.Series when this is really
            required, since pd.Series strided-rolling is significantly less efficient.
            For a np.array it is possible to create very efficient views, but there is
            no such thing as a pd.Series view. Thus, for each stroll, a new series is
            created, inducing a lot of non-feature calculation of overhead.
    window_idx : str, optional
        The window&#39;s index position which will be used as index for the
        feature_window aggregation. Must be either of: `[&#34;begin&#34;, &#34;middle&#34;, &#34;end&#34;]`, by
        default &#34;end&#34;.
    include_final_window: bool, optional
        Whether the final (possibly incomplete) window should be included in the
        strided-window segmentation, by default False.

        .. Note::
            The remarks below apply when ``include_final_window`` is set to True.
            The user should be aware that the last window *might* be incomplete, i.e.;

            - when equally sampled, the last window *might* be smaller than the
              the other windows.
            - when not equally sampled, the last window *might* not include all the
                data points (as the begin-time + window-size comes after the last data
                point).

            Note, that when equally sampled, the last window *will* be a full window
            when:

            - the stride is the sampling rate of the data (or stride = 1 for
              sample-based configurations).&lt;br&gt;
              **Remark**: that when `include_final_window` is set to False, the last
              window (which is a full) window will not be included!
            - *(len * sampling_rate - window_size) % stride = 0*. Remark that the above
              case is a base case of this.
    approve_sparsity: bool, optional
        Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
        irregularly sampled data), by default False.
        If False and sparsity is observed, a warning is raised.

    Notes
    -----
    * This instance withholds a **read-only**-view of the data its values.

    &#34;&#34;&#34;

    # Class variables which are used by subclasses
    win_str_type: DataType
    reset_series_index_b4_segmenting: bool = False
    OUTSIDE_DATA_BOUNDS_WARNING: str = (
        &#34;Some segment indexes are outside the range of the data its index.&#34;
    )

    # Create the named tuple
    _NumpySeriesContainer = namedtuple(
        &#34;SeriesContainer&#34;, [&#34;name&#34;, &#34;values&#34;, &#34;start_indexes&#34;, &#34;end_indexes&#34;]
    )

    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: T,
        strides: Optional[Union[T, List[T]]] = None,
        segment_start_idxs: Optional[np.ndarray] = None,
        segment_end_idxs: Optional[np.ndarray] = None,
        start_idx: Optional[T] = None,
        end_idx: Optional[T] = None,
        func_data_type: Optional[Union[np.array, pd.Series]] = np.array,
        window_idx: Optional[str] = &#34;end&#34;,
        include_final_window: bool = False,
        approve_sparsity: Optional[bool] = False,
    ):
        if strides is not None:
            strides = to_list(strides)

        # Check the passed segment indices
        if segment_start_idxs is not None and segment_end_idxs is not None:
            _check_start_end_array(segment_start_idxs, segment_end_idxs)

        if window is not None:
            assert AttributeParser.check_expected_type(
                [window] + ([] if strides is None else strides), self.win_str_type
            )

        self.window = window
        self.strides = strides

        self.window_idx = window_idx
        self.include_final_window = include_final_window
        self.approve_sparsity = approve_sparsity

        assert func_data_type in SUPPORTED_STROLL_TYPES
        self.data_type = func_data_type

        # 0. Standardize the input
        series_list: List[pd.Series] = to_series_list(data)
        self.series_dtype = AttributeParser.determine_type(series_list)
        self.series_key: Tuple[str, ...] = tuple([str(s.name) for s in series_list])

        # 1. Determine the start index
        self.start, self.end = start_idx, end_idx
        if self.start is None or self.end is None:
            # We always pass start_idx and end_idx from the FeatureCollection.calculate
            # Hence, this code is only useful for testing purposes
            start, end = _determine_bounds(&#34;inner&#34;, series_list)

            # update self.start &amp; self.end if it was not passed
            self.start = start if self.start is None else self.start
            self.end = end if self.end is None else self.end

        # Especially useful when the index dtype differs from the win-stride-dtype
        # e.g. -&gt; performing a int-based stroll on time-indexed data
        # Note: this is very niche and thus requires advanced knowledge
        # TODO: this code can be omitted if we remove TimeIndexSampleStridedRolling
        self._update_start_end_indices_to_stroll_type(series_list)

        # 2. Construct the index ranges
        # Either use the passed segment indices or compute the start or end times of the
        # segments. The segment indices have precedence over the stride (and window) for
        # index computation.
        if segment_start_idxs is not None or segment_end_idxs is not None:
            self.strides = None
            if segment_start_idxs is not None and segment_end_idxs is not None:
                # When both the start and end points are passed, the window does not
                # matter.
                self.window = None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = self._parse_segment_idxs(segment_end_idxs)
            elif segment_start_idxs is not None:  # segment_end_idxs is None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = np_start_times + self._get_np_value(self.window)
            else:  # segment_end_idxs is not None and segment_start_idxs is None
                np_end_times = self._parse_segment_idxs(segment_end_idxs)
                np_start_times = np_end_times - self._get_np_value(self.window)
        else:
            np_start_times = self._construct_start_idxs()
            np_end_times = np_start_times + self._get_np_value(self.window)

        # Check the numpy start and end indices
        _check_start_end_array(np_start_times, np_end_times)

        # 3. Create a new-index which will be used for DataFrame reconstruction
        # Note: the index-name of the first passed series will be re-used as index-name
        self.index = self._get_output_index(
            np_start_times, np_end_times, name=series_list[0].index.name
        )

        # 4. Store the series containers
        self.series_containers = self._construct_series_containers(
            series_list, np_start_times, np_end_times
        )

        # 5. Check the sparsity assumption
        if not self.approve_sparsity and len(self.index):
            for container in self.series_containers:
                # Warn when min != max
                if np.ptp(container.end_indexes - container.start_indexes) != 0:
                    warnings.warn(
                        f&#34;There are gaps in the sequence of the {container.name}&#34;
                        f&#34;-series!&#34;,
                        RuntimeWarning,
                    )

    def _calc_nb_segments_for_stride(self, stride) -&gt; int:
        &#34;&#34;&#34;Calculate the number of output items (segments) for a given single stride.&#34;&#34;&#34;
        nb_feats = max((self.end - self.start - self.window) // stride + 1, 0)
        # Add 1 if there is still some data after (including) the last window its
        # start index - this is only added when `include_last_window` is True.
        nb_feats += self.include_final_window * (
            self.start + stride * nb_feats &lt;= self.end
        )
        return nb_feats

    def _get_np_start_idx_for_stride(self, stride: T) -&gt; np.ndarray:
        &#34;&#34;&#34;Compute the start index for the given single stride.&#34;&#34;&#34;
        # ---------- Efficient numpy code -------
        np_start = self._get_np_value(self.start)
        np_stride = self._get_np_value(stride)
        # Compute the start times (these remain the same for each series)
        return np.arange(
            start=np_start,
            stop=np_start + self._calc_nb_segments_for_stride(stride) * np_stride,
            step=np_stride,
        )

    def _construct_start_idxs(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Construct the start indices of the segments (for all stride values).

        To realize this, we compute the start idxs for each stride and then merge them
        together (without duplicates) in a sorted array.
        &#34;&#34;&#34;
        start_idxs = []
        for stride in self.strides:
            start_idxs += [self._get_np_start_idx_for_stride(stride)]
        # note - np.unique also sorts the array
        return np.unique(np.concatenate(start_idxs))

    def _get_output_index(
        self, start_idxs: np.ndarray, end_idxs: Union[np.ndarray, None], name: str
    ) -&gt; pd.Index:
        &#34;&#34;&#34;Construct the output index.&#34;&#34;&#34;
        if self.window_idx == &#34;end&#34;:
            return pd.Index(end_idxs, name=name)
        elif self.window_idx == &#34;middle&#34;:
            return pd.Index(
                start_idxs + ((end_idxs - start_idxs) / 2),
                name=name,
            )
        elif self.window_idx == &#34;begin&#34;:
            return pd.Index(start_idxs, name=name)
        else:
            raise ValueError(
                f&#34;window index {self.window_idx} must be either of: &#34;
                &#34;[&#39;end&#39;, &#39;middle&#39;, &#39;begin&#39;]&#34;
            )

    def _construct_series_containers(
        self, series_list, np_start_times, np_end_times
    ) -&gt; List[StridedRolling._NumpySeriesContainer]:
        series_containers: List[StridedRolling._NumpySeriesContainer] = []
        for series in series_list:
            if not self.reset_series_index_b4_segmenting:
                np_idx_times = series.index.values
            else:
                np_idx_times = np.arange(len(series))
                # note: using pd.RangeIndex instead of arange gives the same performance

            series_name = series.name
            if self.data_type is np.array:
                # create a non-writeable view of the series
                series = series.values
                series.flags.writeable = False
            elif self.data_type is pd.Series:
                series.values.flags.writeable = False
                series.index.values.flags.writeable = False
            else:
                raise ValueError(&#34;unsupported datatype&#34;)

            series_containers.append(
                StridedRolling._NumpySeriesContainer(
                    name=series_name,
                    values=series,
                    # the slicing will be performed on [ t_start, t_end [
                    # TODO: this can maybe be optimized -&gt; further look into this
                    # np_idx_times, np_start_times, &amp; np_end_times are all sorted!
                    # as we assume &amp; check that the time index is monotonically
                    # increasing &amp; the latter 2 are created using `np.arange()`
                    start_indexes=np.searchsorted(np_idx_times, np_start_times, &#34;left&#34;),
                    end_indexes=np.searchsorted(np_idx_times, np_end_times, &#34;left&#34;),
                )
            )
        return series_containers

    def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Apply a function to the segmented series.

        Parameters
        ----------
        func : FuncWrapper
            The Callable wrapped function which will be applied.

        Returns
        -------
        pd.DataFrame
            The merged output of the function applied to every column in a
            new DataFrame. The DataFrame&#39;s column-names have the format:
                `&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;`.

        Raises
        ------
        ValueError
            If the passed ``func`` tries to adjust the data its read-only view.

        Notes
        -----
        * If ``func`` is only a callable argument, with no additional logic, this
          will only work for a one-to-one mapping, i.e., no multiple feature-output
          columns are supported for this case!&lt;br&gt;
        * If you want to calculate one-to-many, ``func`` should be
          a ``FuncWrapper`` instance and explicitly use
          the ``output_names`` attributes of its constructor.

        &#34;&#34;&#34;
        feat_names = func.output_names

        t_start = time.perf_counter()

        # --- Future work ---
        # would be nice if we could optimize this double for loop with something
        # more vectorized
        #
        # As for now we use a map to apply the function (as this evaluates its
        # expression only once, whereas a list comprehension evaluates its expression
        # every time).
        # See more why: https://stackoverflow.com/a/59838723
        out: np.array
        if func.vectorized:
            # Vectorized function execution

            ## IMPL 1
            ## Results in a high memory peak as a new np.array is created (and thus no
            ## view is being used)
            # out = np.asarray(
            #         func(
            #             *[
            #                 np.array([
            #                     sc.values[sc.start_indexes[idx]: sc.end_indexes[idx]]
            #                     for idx in range(len(self.index))
            #                 ])
            #                 for sc in self.series_containers
            #             ],
            #         )
            #     )

            ## IMPL 2
            ## Is a good implementation (equivalent to the one below), will also fail in
            ## the same cases, but it does not perform clear assertions (with their
            ## accompanied clear messages).
            # out = np.asarray(
            #     func(
            #         *[
            #             _sliding_strided_window_1d(sc.values, self.window, self.stride)
            #             for sc in self.series_containers
            #         ],
            #     )
            # )

            views = []
            for sc in self.series_containers:
                if len(sc.start_indexes) == 0:
                    # There are no feature windows  -&gt; return empty array (see below)
                    views = []
                    break
                elif len(sc.start_indexes) == 1:
                    # There is only 1 feature window (bc no steps in the sliding window)
                    views.append(
                        np.expand_dims(
                            sc.values[sc.start_indexes[0] : sc.end_indexes[0]],
                            axis=0,
                        )
                    )
                else:
                    # There are &gt;1 feature windows (bc &gt;=1 steps in the sliding window)
                    windows = sc.end_indexes - sc.start_indexes
                    strides = sc.start_indexes[1:] - sc.start_indexes[:-1]
                    assert np.all(windows == windows[0]), (
                        &#34;Vectorized functions require same number of samples in each &#34;
                        + &#34;segmented window!&#34;
                    )
                    assert np.all(
                        strides == strides[0]
                    ), &#34;Vectorized functions require same number of samples as stride!&#34;
                    views.append(
                        _sliding_strided_window_1d(
                            sc.values[sc.start_indexes[0] :],
                            windows[0],
                            strides[0],
                            len(self.index),
                        )
                    )

            # Assign empty array as output when there is no view to apply the vectorized
            # function on (this is the case when there is at least for one series no
            # feature windows)
            out = func(*views) if len(views) &gt;= 1 else np.array([])

            out_type = type(out)
            out = np.asarray(out)
            # When multiple outputs are returned (= tuple) they should be transposed
            # when combining into an array
            out = out.T if out_type is tuple else out

        else:
            # Sequential function execution (default)
            out = np.array(
                list(
                    map(
                        func,
                        *[
                            [
                                sc.values[sc.start_indexes[idx] : sc.end_indexes[idx]]
                                for idx in range(len(self.index))
                            ]
                            for sc in self.series_containers
                        ],
                    )
                )
            )

        # Check if the function output is valid.
        # This assertion will be raised when e.g. np.max is applied vectorized without
        # specifying axis=1.
        assert out.ndim &gt; 0, &#34;Vectorized function returned only 1 (non-array) value!&#34;

        # Aggregate function output in a dictionary
        feat_out = {}
        if out.ndim == 1 and not len(out):
            # When there are no features calculated (due to no feature windows)
            assert not len(self.index)
            for f_name in feat_names:
                # Will be discarded (bc no index)
                feat_out[self._create_feat_col_name(f_name)] = None
        elif out.ndim == 1 or (out.ndim == 2 and out.shape[1] == 1):
            assert len(feat_names) == 1, f&#34;Func {func} returned more than 1 output!&#34;
            feat_out[self._create_feat_col_name(feat_names[0])] = out.flatten()
        else:
            assert out.ndim == 2 and out.shape[1] &gt; 1
            assert (
                len(feat_names) == out.shape[1]
            ), f&#34;Func {func} returned incorrect number of outputs ({out.shape[1]})!&#34;
            for col_idx in range(out.shape[1]):
                feat_out[self._create_feat_col_name(feat_names[col_idx])] = out[
                    :, col_idx
                ]

        elapsed = time.perf_counter() - t_start
        log_strides = (
            &#34;manual&#34; if self.strides is None else tuple(map(str, self.strides))
        )
        log_window = &#34;manual&#34; if self.window is None else self.window
        logger.info(
            f&#34;Finished function [{_get_name(func.func)}] on &#34;
            f&#34;{[self.series_key]} with window-stride [{log_window}, {log_strides}] &#34;
            f&#34;with output {list(feat_out.keys())} in [{elapsed} seconds]!&#34;
        )

        return pd.DataFrame(index=self.index, data=feat_out)

    # --------------------------------- STATIC METHODS ---------------------------------
    @staticmethod
    def _get_np_value(val):
        # Convert everything to int64
        if isinstance(val, pd.Timestamp):
            return val.to_datetime64()
        elif isinstance(val, pd.Timedelta):
            return val.to_timedelta64()
        else:
            return val

    @staticmethod
    def construct_output_index(
        series_keys: Union[str, Tuple[str, ...]], feat_name: str, win_str: str
    ) -&gt; str:
        series_keys = to_tuple(series_keys)
        return f&#34;{&#39;|&#39;.join(series_keys)}__{feat_name}__w={win_str}&#34;

    # ----------------------------- OVERRIDE THESE METHODS -----------------------------
    @abstractmethod
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        # NOTE: This method will only be implemented (with code != pass) in the
        # TimeIndexSampleStridedRolling
        raise NotImplementedError

    @abstractmethod
    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Check the segment indexes array to lie between self.start and self.end and
        convert it to the correct dtype (if necessary).&#34;&#34;&#34;
        raise NotImplementedError

    @abstractmethod
    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        raise NotImplementedError</code></pre>
</details>
<div class="desc"><p>Custom time-based sliding window with stride.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd><code>pd.Series</code> or <code>pd.DataFrame</code> to slide over, the index must be either
numeric or a <code>pd.DatetimeIndex</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[float, pd.Timedelta]</code></dt>
<dd>Either an int, float, or <code>pd.Timedelta</code>, representing the sliding window size
in terms of the index (in case of a int or float) or the sliding window duration
(in case of <code>pd.Timedelta</code>).</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]]</code>, optional</dt>
<dd>Either a list of int, float, or <code>pd.Timedelta</code>, representing the stride sizes
in terms of the index (in case of a int or float) or the stride duration (in
case of <code>pd.Timedelta</code>). By default None.</dd>
<dt><strong><code>segment_start_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The start indices for the segmented windows. If not provided, the start indices
will be computed from the data using the passed <code>strides</code> or by using the
<code>segment_end_idxs</code> (if not none) + <code>window</code>. By default None.</dd>
<dt><strong><code>segment_end_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The end indices for the segmented windows. If not provided, the end indices will
be computed from either (1) the data using the passed <code>window</code> + <code>strides</code>
or (2) the <code>segment_start_idxs</code> + <code>window</code>, By default None.<div class="admonition note">
<p class="admonition-title">Note</p>
When you pass arrays to both <code>segment_start_idxs</code> and
<code>segment_end_idxs</code>, the corresponding index-values of these arrays will be
used as segment-ranges. As a result, the following properties must be met:<ul>
<li>both arrays should have equal length</li>
<li>all values in <code>segment_start_idxs</code> should be &lt;= <code>segment_end_idxs</code></li>
</ul>
</div>
</dd>
<dt><strong><code>start_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The start-index which will be used for each series passed to <code>data</code>. This is
especially useful if multiple <code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code> instances are created and the
user want to ensure same (start-)indexes for each of them.</dd>
<dt><strong><code>end_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The end-index which will be used as sliding end-limit for each series passed to
<code>data</code>.</dd>
<dt><strong><code>func_data_type</code></strong> :&ensp;<code>Union[np.array, pd.Series]</code>, optional</dt>
<dd>The data type of the stroll (either np.array or pd.Series), by default np.array.
<br><div class="admonition note">
<p class="admonition-title">Note</p>
Make sure to only set this argument to pd.Series when this is really
required, since pd.Series strided-rolling is significantly less efficient.
For a np.array it is possible to create very efficient views, but there is
no such thing as a pd.Series view. Thus, for each stroll, a new series is
created, inducing a lot of non-feature calculation of overhead.</div>
</dd>
<dt><strong><code>window_idx</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The window's index position which will be used as index for the
feature_window aggregation. Must be either of: <code>["begin", "middle", "end"]</code>, by
default "end".</dd>
<dt><strong><code>include_final_window</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>
<p>Whether the final (possibly incomplete) window should be included in the
strided-window segmentation, by default False.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The remarks below apply when <code>include_final_window</code> is set to True.
The user should be aware that the last window <em>might</em> be incomplete, i.e.;</p>
<ul>
<li>when equally sampled, the last window <em>might</em> be smaller than the
the other windows.</li>
<li>when not equally sampled, the last window <em>might</em> not include all the
data points (as the begin-time + window-size comes after the last data
point).</li>
</ul>
<p>Note, that when equally sampled, the last window <em>will</em> be a full window
when:</p>
<ul>
<li>the stride is the sampling rate of the data (or stride = 1 for
sample-based configurations).<br>
<strong>Remark</strong>: that when <code>include_final_window</code> is set to False, the last
window (which is a full) window will not be included!</li>
<li><em>(len * sampling_rate - window_size) % stride = 0</em>. Remark that the above
case is a base case of this.</li>
</ul>
</div>
</dd>
<dt><strong><code>approve_sparsity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
irregularly sampled data), by default False.
If False and sparsity is observed, a warning is raised.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>This instance withholds a <strong>read-only</strong>-view of the data its values.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling">SequenceStridedRolling</a></li>
<li><a title="tsflex.features.segmenter.strided_rolling.TimeStridedRolling" href="#tsflex.features.segmenter.strided_rolling.TimeStridedRolling">TimeStridedRolling</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling.win_str_type"><code class="name">var <span class="ident">win_str_type</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling.reset_series_index_b4_segmenting"><code class="name">var <span class="ident">reset_series_index_b4_segmenting</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling.OUTSIDE_DATA_BOUNDS_WARNING"><code class="name">var <span class="ident">OUTSIDE_DATA_BOUNDS_WARNING</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling.construct_output_index"><code class="name flex">
<span>def <span class="ident">construct_output_index</span></span>(<span>series_keys, feat_name, win_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def construct_output_index(
    series_keys: Union[str, Tuple[str, ...]], feat_name: str, win_str: str
) -&gt; str:
    series_keys = to_tuple(series_keys)
    return f&#34;{&#39;|&#39;.join(series_keys)}__{feat_name}__w={win_str}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func"><code class="name flex">
<span>def <span class="ident">apply_func</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Apply a function to the segmented series.

    Parameters
    ----------
    func : FuncWrapper
        The Callable wrapped function which will be applied.

    Returns
    -------
    pd.DataFrame
        The merged output of the function applied to every column in a
        new DataFrame. The DataFrame&#39;s column-names have the format:
            `&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;`.

    Raises
    ------
    ValueError
        If the passed ``func`` tries to adjust the data its read-only view.

    Notes
    -----
    * If ``func`` is only a callable argument, with no additional logic, this
      will only work for a one-to-one mapping, i.e., no multiple feature-output
      columns are supported for this case!&lt;br&gt;
    * If you want to calculate one-to-many, ``func`` should be
      a ``FuncWrapper`` instance and explicitly use
      the ``output_names`` attributes of its constructor.

    &#34;&#34;&#34;
    feat_names = func.output_names

    t_start = time.perf_counter()

    # --- Future work ---
    # would be nice if we could optimize this double for loop with something
    # more vectorized
    #
    # As for now we use a map to apply the function (as this evaluates its
    # expression only once, whereas a list comprehension evaluates its expression
    # every time).
    # See more why: https://stackoverflow.com/a/59838723
    out: np.array
    if func.vectorized:
        # Vectorized function execution

        ## IMPL 1
        ## Results in a high memory peak as a new np.array is created (and thus no
        ## view is being used)
        # out = np.asarray(
        #         func(
        #             *[
        #                 np.array([
        #                     sc.values[sc.start_indexes[idx]: sc.end_indexes[idx]]
        #                     for idx in range(len(self.index))
        #                 ])
        #                 for sc in self.series_containers
        #             ],
        #         )
        #     )

        ## IMPL 2
        ## Is a good implementation (equivalent to the one below), will also fail in
        ## the same cases, but it does not perform clear assertions (with their
        ## accompanied clear messages).
        # out = np.asarray(
        #     func(
        #         *[
        #             _sliding_strided_window_1d(sc.values, self.window, self.stride)
        #             for sc in self.series_containers
        #         ],
        #     )
        # )

        views = []
        for sc in self.series_containers:
            if len(sc.start_indexes) == 0:
                # There are no feature windows  -&gt; return empty array (see below)
                views = []
                break
            elif len(sc.start_indexes) == 1:
                # There is only 1 feature window (bc no steps in the sliding window)
                views.append(
                    np.expand_dims(
                        sc.values[sc.start_indexes[0] : sc.end_indexes[0]],
                        axis=0,
                    )
                )
            else:
                # There are &gt;1 feature windows (bc &gt;=1 steps in the sliding window)
                windows = sc.end_indexes - sc.start_indexes
                strides = sc.start_indexes[1:] - sc.start_indexes[:-1]
                assert np.all(windows == windows[0]), (
                    &#34;Vectorized functions require same number of samples in each &#34;
                    + &#34;segmented window!&#34;
                )
                assert np.all(
                    strides == strides[0]
                ), &#34;Vectorized functions require same number of samples as stride!&#34;
                views.append(
                    _sliding_strided_window_1d(
                        sc.values[sc.start_indexes[0] :],
                        windows[0],
                        strides[0],
                        len(self.index),
                    )
                )

        # Assign empty array as output when there is no view to apply the vectorized
        # function on (this is the case when there is at least for one series no
        # feature windows)
        out = func(*views) if len(views) &gt;= 1 else np.array([])

        out_type = type(out)
        out = np.asarray(out)
        # When multiple outputs are returned (= tuple) they should be transposed
        # when combining into an array
        out = out.T if out_type is tuple else out

    else:
        # Sequential function execution (default)
        out = np.array(
            list(
                map(
                    func,
                    *[
                        [
                            sc.values[sc.start_indexes[idx] : sc.end_indexes[idx]]
                            for idx in range(len(self.index))
                        ]
                        for sc in self.series_containers
                    ],
                )
            )
        )

    # Check if the function output is valid.
    # This assertion will be raised when e.g. np.max is applied vectorized without
    # specifying axis=1.
    assert out.ndim &gt; 0, &#34;Vectorized function returned only 1 (non-array) value!&#34;

    # Aggregate function output in a dictionary
    feat_out = {}
    if out.ndim == 1 and not len(out):
        # When there are no features calculated (due to no feature windows)
        assert not len(self.index)
        for f_name in feat_names:
            # Will be discarded (bc no index)
            feat_out[self._create_feat_col_name(f_name)] = None
    elif out.ndim == 1 or (out.ndim == 2 and out.shape[1] == 1):
        assert len(feat_names) == 1, f&#34;Func {func} returned more than 1 output!&#34;
        feat_out[self._create_feat_col_name(feat_names[0])] = out.flatten()
    else:
        assert out.ndim == 2 and out.shape[1] &gt; 1
        assert (
            len(feat_names) == out.shape[1]
        ), f&#34;Func {func} returned incorrect number of outputs ({out.shape[1]})!&#34;
        for col_idx in range(out.shape[1]):
            feat_out[self._create_feat_col_name(feat_names[col_idx])] = out[
                :, col_idx
            ]

    elapsed = time.perf_counter() - t_start
    log_strides = (
        &#34;manual&#34; if self.strides is None else tuple(map(str, self.strides))
    )
    log_window = &#34;manual&#34; if self.window is None else self.window
    logger.info(
        f&#34;Finished function [{_get_name(func.func)}] on &#34;
        f&#34;{[self.series_key]} with window-stride [{log_window}, {log_strides}] &#34;
        f&#34;with output {list(feat_out.keys())} in [{elapsed} seconds]!&#34;
    )

    return pd.DataFrame(index=self.index, data=feat_out)</code></pre>
</details>
<div class="desc"><p>Apply a function to the segmented series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>FuncWrapper</code></dt>
<dd>The Callable wrapped function which will be applied.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>The merged output of the function applied to every column in a
new DataFrame. The DataFrame's column-names have the format:
<code>&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the passed <code>func</code> tries to adjust the data its read-only view.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>If <code>func</code> is only a callable argument, with no additional logic, this
will only work for a one-to-one mapping, i.e., no multiple feature-output
columns are supported for this case!<br></li>
<li>If you want to calculate one-to-many, <code>func</code> should be
a <code>FuncWrapper</code> instance and explicitly use
the <code>output_names</code> attributes of its constructor.</li>
</ul></div>
</dd>
</dl>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling"><code class="flex name class">
<span>class <span class="ident">SequenceStridedRolling</span></span>
<span>(</span><span>data, window, strides=None, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SequenceStridedRolling(StridedRolling):
    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: float,
        strides: Optional[Union[float, List[float]]] = None,
        *args,
        **kwargs,
    ):
        # Set the data type &amp; call the super constructor
        self.win_str_type = DataType.SEQUENCE
        super().__init__(data, window, strides, *args, **kwargs)

    # ------------------------------- Overridden methods -------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        pass

    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        if any((segment_idxs &lt; self.start) | (segment_idxs &gt; self.end)):
            warnings.warn(self.OUTSIDE_DATA_BOUNDS_WARNING, RuntimeWarning)
        return segment_idxs

    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        if self.window is not None:
            win_str = str(self.window)
        else:
            win_str = &#34;manual&#34;
        return self.construct_output_index(
            series_keys=self.series_key, feat_name=feat_name, win_str=win_str
        )</code></pre>
</details>
<div class="desc"><p>Custom time-based sliding window with stride.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd><code>pd.Series</code> or <code>pd.DataFrame</code> to slide over, the index must be either
numeric or a <code>pd.DatetimeIndex</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[float, pd.Timedelta]</code></dt>
<dd>Either an int, float, or <code>pd.Timedelta</code>, representing the sliding window size
in terms of the index (in case of a int or float) or the sliding window duration
(in case of <code>pd.Timedelta</code>).</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]]</code>, optional</dt>
<dd>Either a list of int, float, or <code>pd.Timedelta</code>, representing the stride sizes
in terms of the index (in case of a int or float) or the stride duration (in
case of <code>pd.Timedelta</code>). By default None.</dd>
<dt><strong><code>segment_start_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The start indices for the segmented windows. If not provided, the start indices
will be computed from the data using the passed <code>strides</code> or by using the
<code>segment_end_idxs</code> (if not none) + <code>window</code>. By default None.</dd>
<dt><strong><code>segment_end_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The end indices for the segmented windows. If not provided, the end indices will
be computed from either (1) the data using the passed <code>window</code> + <code>strides</code>
or (2) the <code>segment_start_idxs</code> + <code>window</code>, By default None.<div class="admonition note">
<p class="admonition-title">Note</p>
When you pass arrays to both <code>segment_start_idxs</code> and
<code>segment_end_idxs</code>, the corresponding index-values of these arrays will be
used as segment-ranges. As a result, the following properties must be met:<ul>
<li>both arrays should have equal length</li>
<li>all values in <code>segment_start_idxs</code> should be &lt;= <code>segment_end_idxs</code></li>
</ul>
</div>
</dd>
<dt><strong><code>start_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The start-index which will be used for each series passed to <code>data</code>. This is
especially useful if multiple <code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code> instances are created and the
user want to ensure same (start-)indexes for each of them.</dd>
<dt><strong><code>end_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The end-index which will be used as sliding end-limit for each series passed to
<code>data</code>.</dd>
<dt><strong><code>func_data_type</code></strong> :&ensp;<code>Union[np.array, pd.Series]</code>, optional</dt>
<dd>The data type of the stroll (either np.array or pd.Series), by default np.array.
<br><div class="admonition note">
<p class="admonition-title">Note</p>
Make sure to only set this argument to pd.Series when this is really
required, since pd.Series strided-rolling is significantly less efficient.
For a np.array it is possible to create very efficient views, but there is
no such thing as a pd.Series view. Thus, for each stroll, a new series is
created, inducing a lot of non-feature calculation of overhead.</div>
</dd>
<dt><strong><code>window_idx</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The window's index position which will be used as index for the
feature_window aggregation. Must be either of: <code>["begin", "middle", "end"]</code>, by
default "end".</dd>
<dt><strong><code>include_final_window</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>
<p>Whether the final (possibly incomplete) window should be included in the
strided-window segmentation, by default False.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The remarks below apply when <code>include_final_window</code> is set to True.
The user should be aware that the last window <em>might</em> be incomplete, i.e.;</p>
<ul>
<li>when equally sampled, the last window <em>might</em> be smaller than the
the other windows.</li>
<li>when not equally sampled, the last window <em>might</em> not include all the
data points (as the begin-time + window-size comes after the last data
point).</li>
</ul>
<p>Note, that when equally sampled, the last window <em>will</em> be a full window
when:</p>
<ul>
<li>the stride is the sampling rate of the data (or stride = 1 for
sample-based configurations).<br>
<strong>Remark</strong>: that when <code>include_final_window</code> is set to False, the last
window (which is a full) window will not be included!</li>
<li><em>(len * sampling_rate - window_size) % stride = 0</em>. Remark that the above
case is a base case of this.</li>
</ul>
</div>
</dd>
<dt><strong><code>approve_sparsity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
irregularly sampled data), by default False.
If False and sparsity is observed, a warning is raised.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>This instance withholds a <strong>read-only</strong>-view of the data its values.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling" href="#tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling">TimeIndexSampleStridedRolling</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.win_str_type"><code class="name">var <span class="ident">win_str_type</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.reset_series_index_b4_segmenting"><code class="name">var <span class="ident">reset_series_index_b4_segmenting</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.OUTSIDE_DATA_BOUNDS_WARNING"><code class="name">var <span class="ident">OUTSIDE_DATA_BOUNDS_WARNING</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.apply_func"><code class="name flex">
<span>def <span class="ident">apply_func</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code>.<code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func">apply_func</a></code>
</p>
<div class="desc inherited"><p>Apply a function to the segmented series â€¦</p></div>
</dd>
</dl>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeStridedRolling"><code class="flex name class">
<span>class <span class="ident">TimeStridedRolling</span></span>
<span>(</span><span>data, window, strides=None, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TimeStridedRolling(StridedRolling):
    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: pd.Timedelta,
        strides: Optional[Union[pd.Timedelta, List[pd.Timedelta]]] = None,
        *args,
        **kwargs,
    ):
        # Check that each series / dataframe has the same tz
        data = to_series_list(data)
        tz_index = data[0].index.tz
        for data_entry in to_series_list(data)[1:]:
            assert (
                data_entry.index.tz == tz_index
            ), &#34;strided rolling input data must all have same timezone&#34;
        self._tz_index = tz_index
        # Set the data type &amp; call the super constructor
        self.win_str_type = DataType.TIME
        super().__init__(data, window, strides, *args, **kwargs)

    # -------------------------------- Extended methods --------------------------------
    def _get_output_index(
        self, start_idxs: np.ndarray, end_idxs: np.ndarray, name: str
    ) -&gt; pd.Index:
        assert start_idxs.dtype.type == np.datetime64
        assert end_idxs.dtype.type == np.datetime64
        start_idxs = pd.to_datetime(start_idxs, utc=True).tz_convert(self._tz_index)
        end_idxs = pd.to_datetime(end_idxs, utc=True).tz_convert(self._tz_index)
        return super()._get_output_index(start_idxs, end_idxs, name)

    # ------------------------------- Overridden methods -------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        pass

    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        segment_idxs = segment_idxs.astype(&#34;datetime64&#34;)
        start_, end_ = self.start, self.end
        if start_.tz is not None:
            # Convert to UTC (allowing comparison with the segment_idxs)
            assert end_.tz is not None
            start_ = start_.tz_convert(None)
            end_ = end_.tz_convert(None)
        if any((segment_idxs &lt; start_) | (segment_idxs &gt; end_)):
            warnings.warn(self.OUTSIDE_DATA_BOUNDS_WARNING, RuntimeWarning)
        return segment_idxs

    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        # Convert win to time-string if available :)
        if self.window is not None:
            win_str = timedelta_to_str(self.window)
        else:
            win_str = &#34;manual&#34;
        return self.construct_output_index(
            series_keys=self.series_key, feat_name=feat_name, win_str=win_str
        )</code></pre>
</details>
<div class="desc"><p>Custom time-based sliding window with stride.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd><code>pd.Series</code> or <code>pd.DataFrame</code> to slide over, the index must be either
numeric or a <code>pd.DatetimeIndex</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[float, pd.Timedelta]</code></dt>
<dd>Either an int, float, or <code>pd.Timedelta</code>, representing the sliding window size
in terms of the index (in case of a int or float) or the sliding window duration
(in case of <code>pd.Timedelta</code>).</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]]</code>, optional</dt>
<dd>Either a list of int, float, or <code>pd.Timedelta</code>, representing the stride sizes
in terms of the index (in case of a int or float) or the stride duration (in
case of <code>pd.Timedelta</code>). By default None.</dd>
<dt><strong><code>segment_start_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The start indices for the segmented windows. If not provided, the start indices
will be computed from the data using the passed <code>strides</code> or by using the
<code>segment_end_idxs</code> (if not none) + <code>window</code>. By default None.</dd>
<dt><strong><code>segment_end_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The end indices for the segmented windows. If not provided, the end indices will
be computed from either (1) the data using the passed <code>window</code> + <code>strides</code>
or (2) the <code>segment_start_idxs</code> + <code>window</code>, By default None.<div class="admonition note">
<p class="admonition-title">Note</p>
When you pass arrays to both <code>segment_start_idxs</code> and
<code>segment_end_idxs</code>, the corresponding index-values of these arrays will be
used as segment-ranges. As a result, the following properties must be met:<ul>
<li>both arrays should have equal length</li>
<li>all values in <code>segment_start_idxs</code> should be &lt;= <code>segment_end_idxs</code></li>
</ul>
</div>
</dd>
<dt><strong><code>start_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The start-index which will be used for each series passed to <code>data</code>. This is
especially useful if multiple <code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code> instances are created and the
user want to ensure same (start-)indexes for each of them.</dd>
<dt><strong><code>end_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The end-index which will be used as sliding end-limit for each series passed to
<code>data</code>.</dd>
<dt><strong><code>func_data_type</code></strong> :&ensp;<code>Union[np.array, pd.Series]</code>, optional</dt>
<dd>The data type of the stroll (either np.array or pd.Series), by default np.array.
<br><div class="admonition note">
<p class="admonition-title">Note</p>
Make sure to only set this argument to pd.Series when this is really
required, since pd.Series strided-rolling is significantly less efficient.
For a np.array it is possible to create very efficient views, but there is
no such thing as a pd.Series view. Thus, for each stroll, a new series is
created, inducing a lot of non-feature calculation of overhead.</div>
</dd>
<dt><strong><code>window_idx</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The window's index position which will be used as index for the
feature_window aggregation. Must be either of: <code>["begin", "middle", "end"]</code>, by
default "end".</dd>
<dt><strong><code>include_final_window</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>
<p>Whether the final (possibly incomplete) window should be included in the
strided-window segmentation, by default False.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The remarks below apply when <code>include_final_window</code> is set to True.
The user should be aware that the last window <em>might</em> be incomplete, i.e.;</p>
<ul>
<li>when equally sampled, the last window <em>might</em> be smaller than the
the other windows.</li>
<li>when not equally sampled, the last window <em>might</em> not include all the
data points (as the begin-time + window-size comes after the last data
point).</li>
</ul>
<p>Note, that when equally sampled, the last window <em>will</em> be a full window
when:</p>
<ul>
<li>the stride is the sampling rate of the data (or stride = 1 for
sample-based configurations).<br>
<strong>Remark</strong>: that when <code>include_final_window</code> is set to False, the last
window (which is a full) window will not be included!</li>
<li><em>(len * sampling_rate - window_size) % stride = 0</em>. Remark that the above
case is a base case of this.</li>
</ul>
</div>
</dd>
<dt><strong><code>approve_sparsity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
irregularly sampled data), by default False.
If False and sparsity is observed, a warning is raised.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>This instance withholds a <strong>read-only</strong>-view of the data its values.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.TimeStridedRolling.win_str_type"><code class="name">var <span class="ident">win_str_type</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeStridedRolling.reset_series_index_b4_segmenting"><code class="name">var <span class="ident">reset_series_index_b4_segmenting</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeStridedRolling.OUTSIDE_DATA_BOUNDS_WARNING"><code class="name">var <span class="ident">OUTSIDE_DATA_BOUNDS_WARNING</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.TimeStridedRolling.apply_func"><code class="name flex">
<span>def <span class="ident">apply_func</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code>.<code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func">apply_func</a></code>
</p>
<div class="desc inherited"><p>Apply a function to the segmented series â€¦</p></div>
</dd>
</dl>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling"><code class="flex name class">
<span>class <span class="ident">TimeIndexSampleStridedRolling</span></span>
<span>(</span><span>data, window, strides=None, segment_start_idxs=None, segment_end_idxs=None, *args, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TimeIndexSampleStridedRolling(SequenceStridedRolling):
    def __init__(
        self,
        # TODO -&gt; update arguments
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: int,
        strides: Optional[Union[int, List[int]]] = None,
        segment_start_idxs: Optional[np.ndarray] = None,
        segment_end_idxs: Optional[np.ndarray] = None,
        *args,
        **kwargs,
    ):
        &#34;&#34;&#34;
        .. Warning::
            When `data` consists of multiple independently sampled series
            (e.g. feature functions which take multiple series as input),
            The time-**index of each series**: \n
            - must _roughly_ **share** the same **sample frequency**.
            - will be first time-aligned before transitioning to sample-segmentation by
              using the inner bounds

        .. Note::
            `TimeIndexSampleStridedRolling` **does not support** the
            ``segment_start_idxs`` and ``segment_end_idxs`` arguments. Setting these
            will raise a NotImplementedError.

        &#34;&#34;&#34;
        if segment_start_idxs is not None or segment_end_idxs is not None:
            raise NotImplementedError(
                &#34;TimeIndexSampleStridedRolling is not implemented to support passing&#34;
                + &#34;segment_start_idxs or segment_end_idxs&#34;
            )

        # We want to reset the index as its type differs from the passed win-stride
        # configs
        self.reset_series_index_b4_segmenting = True

        series_list = to_series_list(data)
        if isinstance(data, list) and len(data) &gt; 1:
            # Slice data into its inner range so that the start position
            # is aligned (when we will use sample-based methodologies)
            start, end = _determine_bounds(&#34;inner&#34;, series_list)
            series_list = [s[start:end] for s in series_list]
            kwargs.update({&#34;start_idx&#34;: start, &#34;end_idx&#34;: end})

        # We retain the first series list to stitch back the output index
        self._series_index = series_list[0].index

        # pass the sliced series list instead of data
        super().__init__(series_list, window, strides, *args, **kwargs)

        assert self.series_dtype == DataType.TIME

        # we want to assure that the window-stride arguments are integers (samples)
        assert all(isinstance(p, int) for p in [self.window] + self.strides)

    def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
        # Apply the function and stitch back the time-index
        df = super().apply_func(func)
        df.index = self._series_index[df.index]
        return df

    # ---------------------------- Overridden methods ------------------------------
    def _update_start_end_indices_to_stroll_type(self, series_list: List[pd.Series]):
        # update the start and end times to the sequence datatype
        self.start, self.end = np.searchsorted(
            series_list[0].index.values,
            [self.start.to_datetime64(), self.end.to_datetime64()],
            &#34;left&#34;,
        )</code></pre>
</details>
<div class="desc"><p>Custom time-based sliding window with stride.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd><code>pd.Series</code> or <code>pd.DataFrame</code> to slide over, the index must be either
numeric or a <code>pd.DatetimeIndex</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[float, pd.Timedelta]</code></dt>
<dd>Either an int, float, or <code>pd.Timedelta</code>, representing the sliding window size
in terms of the index (in case of a int or float) or the sliding window duration
(in case of <code>pd.Timedelta</code>).</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]]</code>, optional</dt>
<dd>Either a list of int, float, or <code>pd.Timedelta</code>, representing the stride sizes
in terms of the index (in case of a int or float) or the stride duration (in
case of <code>pd.Timedelta</code>). By default None.</dd>
<dt><strong><code>segment_start_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The start indices for the segmented windows. If not provided, the start indices
will be computed from the data using the passed <code>strides</code> or by using the
<code>segment_end_idxs</code> (if not none) + <code>window</code>. By default None.</dd>
<dt><strong><code>segment_end_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The end indices for the segmented windows. If not provided, the end indices will
be computed from either (1) the data using the passed <code>window</code> + <code>strides</code>
or (2) the <code>segment_start_idxs</code> + <code>window</code>, By default None.<div class="admonition note">
<p class="admonition-title">Note</p>
When you pass arrays to both <code>segment_start_idxs</code> and
<code>segment_end_idxs</code>, the corresponding index-values of these arrays will be
used as segment-ranges. As a result, the following properties must be met:<ul>
<li>both arrays should have equal length</li>
<li>all values in <code>segment_start_idxs</code> should be &lt;= <code>segment_end_idxs</code></li>
</ul>
</div>
</dd>
<dt><strong><code>start_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The start-index which will be used for each series passed to <code>data</code>. This is
especially useful if multiple <code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code> instances are created and the
user want to ensure same (start-)indexes for each of them.</dd>
<dt><strong><code>end_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The end-index which will be used as sliding end-limit for each series passed to
<code>data</code>.</dd>
<dt><strong><code>func_data_type</code></strong> :&ensp;<code>Union[np.array, pd.Series]</code>, optional</dt>
<dd>The data type of the stroll (either np.array or pd.Series), by default np.array.
<br><div class="admonition note">
<p class="admonition-title">Note</p>
Make sure to only set this argument to pd.Series when this is really
required, since pd.Series strided-rolling is significantly less efficient.
For a np.array it is possible to create very efficient views, but there is
no such thing as a pd.Series view. Thus, for each stroll, a new series is
created, inducing a lot of non-feature calculation of overhead.</div>
</dd>
<dt><strong><code>window_idx</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The window's index position which will be used as index for the
feature_window aggregation. Must be either of: <code>["begin", "middle", "end"]</code>, by
default "end".</dd>
<dt><strong><code>include_final_window</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>
<p>Whether the final (possibly incomplete) window should be included in the
strided-window segmentation, by default False.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The remarks below apply when <code>include_final_window</code> is set to True.
The user should be aware that the last window <em>might</em> be incomplete, i.e.;</p>
<ul>
<li>when equally sampled, the last window <em>might</em> be smaller than the
the other windows.</li>
<li>when not equally sampled, the last window <em>might</em> not include all the
data points (as the begin-time + window-size comes after the last data
point).</li>
</ul>
<p>Note, that when equally sampled, the last window <em>will</em> be a full window
when:</p>
<ul>
<li>the stride is the sampling rate of the data (or stride = 1 for
sample-based configurations).<br>
<strong>Remark</strong>: that when <code>include_final_window</code> is set to False, the last
window (which is a full) window will not be included!</li>
<li><em>(len * sampling_rate - window_size) % stride = 0</em>. Remark that the above
case is a base case of this.</li>
</ul>
</div>
</dd>
<dt><strong><code>approve_sparsity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
irregularly sampled data), by default False.
If False and sparsity is observed, a warning is raised.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>This instance withholds a <strong>read-only</strong>-view of the data its values.</li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When <code>data</code> consists of multiple independently sampled series
(e.g. feature functions which take multiple series as input),
The time-<strong>index of each series</strong>: </p>
<ul>
<li>must <em>roughly</em> <strong>share</strong> the same <strong>sample frequency</strong>.</li>
<li>will be first time-aligned before transitioning to sample-segmentation by
using the inner bounds</li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code><a title="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling" href="#tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling">TimeIndexSampleStridedRolling</a></code> <strong>does not support</strong> the
<code>segment_start_idxs</code> and <code>segment_end_idxs</code> arguments. Setting these
will raise a NotImplementedError.</p>
</div></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling">SequenceStridedRolling</a></li>
<li><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.win_str_type"><code class="name">var <span class="ident">win_str_type</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.reset_series_index_b4_segmenting"><code class="name">var <span class="ident">reset_series_index_b4_segmenting</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.OUTSIDE_DATA_BOUNDS_WARNING"><code class="name">var <span class="ident">OUTSIDE_DATA_BOUNDS_WARNING</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.apply_func"><code class="name flex">
<span>def <span class="ident">apply_func</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
    # Apply the function and stitch back the time-index
    df = super().apply_func(func)
    df.index = self._series_index[df.index]
    return df</code></pre>
</details>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling">SequenceStridedRolling</a></code>.<code><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.apply_func">apply_func</a></code>
</p>
<div class="desc inherited"><p>Apply a function to the segmented series â€¦</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</article>
<div class="sidebar_container">
<nav id="sidebar">
<div id="sidebar_content">
<header>
<div style="text-align: left; padding-top: 15px;">
<a class="homelink" rel="home" title="tsflex home" href="/tsflex/">
<img src="https://raw.githubusercontent.com/predict-idlab/tsflex/main/docs/_static/logo.png"
alt="logo should be displayed here" width="95%"></a>
</div>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tsflex.features.segmenter" href="index.html">.segmenter</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling" href="#tsflex.features.segmenter.strided_rolling.StridedRolling">StridedRolling</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling.construct_output_index" href="#tsflex.features.segmenter.strided_rolling.StridedRolling.construct_output_index">construct_output_index</a></code></li>
<li><code><a title="tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.StridedRolling.apply_func">apply_func</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling">SequenceStridedRolling</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling.apply_func">apply_func</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsflex.features.segmenter.strided_rolling.TimeStridedRolling" href="#tsflex.features.segmenter.strided_rolling.TimeStridedRolling">TimeStridedRolling</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.strided_rolling.TimeStridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.TimeStridedRolling.apply_func">apply_func</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling" href="#tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling">TimeIndexSampleStridedRolling</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.apply_func" href="#tsflex.features.segmenter.strided_rolling.TimeIndexSampleStridedRolling.apply_func">apply_func</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</nav>
</div>
</main>
<script>
const sidebar = document.querySelector("body > main > div");
const sidebar_nav = document.querySelector("body > main > div > nav");
const sidebar_content = document.getElementById("sidebar_content");
document.getElementById("index_button_button").onclick = function () {
sidebar.classList.toggle('sidebar_small');
sidebar_nav.classList.toggle('hide_content');
sidebar_content.classList.toggle('hide_content');
}
</script>
</body>
</html>