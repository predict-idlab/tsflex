<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>tsflex.features.segmenter API documentation</title>
<meta name="description" content="Series segmentation submodule." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/foundation.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em;padding-left:1em;padding-right:1em}button{display:none}#sidebar{padding:3px;max-width:20em;overflow:hidden;min-width:19.8em}#sidebar > *:last-child{margin-bottom:1cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;border-top:1px solid #ddd;text-align:right}#footer p{}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f1f3f9;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:0.5em;padding:0px}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;max_width:100%;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.info{background:#edfcf4}.admonition.note,.admonition.important{background:#ebf3ff}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#edfcf4}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#ffddcc}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:850px){.sidebar_container{display:flex;transition:0.75s ease}.sidebar_small{width:0;margin:0;padding:0}.hide_content{display:none}button{display:initial;float:left;position:sticky;border:none;height:5ch;width:5ch;border-radius:50%;box-shadow:0px 1px 4px 1px rgba(0,0,0,.2);top:5%;left:100%;transform:translateX(-50%);cursor:pointer}#sidebar{width:25%;height:100vh;overflow:auto;position:sticky;top:0;transition:0.75s ease}#index_button_img{opacity:0.65}#content{max-width:105ch;padding:2em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1em;padding-right:0.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-212611910-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-212611910-1');
</script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://media.discordapp.net/attachments/372491075153166338/852906324417445908/icon.png">
</head>
<body>
<main>
<article id="content">
<button id="index_button_button"><img id="index_button_img"
src="https://image.flaticon.com/icons/png/512/56/56763.png"
alt="" width="33" height="25"></button>
<header>
<h1 class="title">Module <code>tsflex.features.segmenter</code></h1>
</header>
<section id="section-intro">
<p>Series segmentation submodule.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Series segmentation submodule.&#34;&#34;&#34;

__author__ = &#34;Jonas Van Der Donckt&#34;

from .strided_rolling import StridedRolling
from .strided_rolling_factory import StridedRollingFactory

__all__ = [
    &#34;StridedRolling&#34;,
    &#34;StridedRollingFactory&#34;,
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">API reference of <code>tsflex.features.segmenter</code></h2>
<dl>
<dt><code class="name"><a title="tsflex.features.segmenter.strided_rolling" href="strided_rolling.html">.strided_rolling</a></code></dt>
<dd>
<div class="desc"><p>Withholds a (rather) fast implementation of an <strong>index-based</strong> strided rolling window …</p></div>
</dd>
<dt><code class="name"><a title="tsflex.features.segmenter.strided_rolling_factory" href="strided_rolling_factory.html">.strided_rolling_factory</a></code></dt>
<dd>
<div class="desc"><p>Factory class for creating the proper StridedRolling instances …</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="tsflex.features.segmenter.StridedRolling"><code class="flex name class">
<span>class <span class="ident">StridedRolling</span></span>
<span>(</span><span>data, window, strides=None, segment_start_idxs=None, segment_end_idxs=None, start_idx=None, end_idx=None, func_data_type=numpy.ndarray, window_idx='end', include_final_window=False, approve_sparsity=False)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StridedRolling(ABC):
    &#34;&#34;&#34;Custom time-based sliding window with stride.

    Parameters
    ----------
    data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]
        ``pd.Series`` or ``pd.DataFrame`` to slide over, the index must be either
        numeric or a ``pd.DatetimeIndex``.
    window : Union[float, pd.Timedelta]
        Either an int, float, or ``pd.Timedelta``, representing the sliding window size
        in terms of the index (in case of a int or float) or the sliding window duration
        (in case of ``pd.Timedelta``).
    strides : Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]], optional
        Either a list of int, float, or ``pd.Timedelta``, representing the stride sizes
        in terms of the index (in case of a int or float) or the stride duration (in
        case of ``pd.Timedelta``). By default None.
    segment_start_idxs: np.ndarray, optional
        The start indices for the segmented windows. If not provided, the start indices
        will be computed from the data using the passed ``strides`` or by using the
        ``segment_end_idxs`` (if not none) + ``window``. By default None.
    segment_end_idxs: np.ndarray, optional
        The end indices for the segmented windows. If not provided, the end indices will
        be computed from either (1) the data using the passed ``window`` + ``strides``
        or (2) the ``segment_start_idxs`` + ``window``, By default None.
        .. Note::
            When you pass arrays to both ``segment_start_idxs`` and
            ``segment_end_idxs``, the corresponding index-values of these arrays will be
            used as segment-ranges. As a result, the following properties must be met:\n
              - both arrays should have equal length
              - all values in ``segment_start_idxs`` should be &lt;= ``segment_end_idxs``
    start_idx: Union[float, pd.Timestamp], optional
        The start-index which will be used for each series passed to `data`. This is
        especially useful if multiple ``StridedRolling`` instances are created and the
        user want to ensure same (start-)indexes for each of them.
    end_idx: Union[float, pd.Timestamp], optional
        The end-index which will be used as sliding end-limit for each series passed to
        `data`.
    func_data_type: Union[np.array, pd.Series], optional
        The data type of the stroll (either np.array or pd.Series), by default np.array.
        &lt;br&gt;
        .. Note::
            Make sure to only set this argument to pd.Series when this is really
            required, since pd.Series strided-rolling is significantly less efficient.
            For a np.array it is possible to create very efficient views, but there is
            no such thing as a pd.Series view. Thus, for each stroll, a new series is
            created, inducing a lot of non-feature calculation of overhead.
    window_idx : str, optional
        The window&#39;s index position which will be used as index for the
        feature_window aggregation. Must be either of: `[&#34;begin&#34;, &#34;middle&#34;, &#34;end&#34;]`, by
        default &#34;end&#34;.
    include_final_window: bool, optional
        Whether the final (possibly incomplete) window should be included in the
        strided-window segmentation, by default False.

        .. Note::
            The remarks below apply when ``include_final_window`` is set to True.
            The user should be aware that the last window *might* be incomplete, i.e.;

            - when equally sampled, the last window *might* be smaller than the
              the other windows.
            - when not equally sampled, the last window *might* not include all the
                data points (as the begin-time + window-size comes after the last data
                point).

            Note, that when equally sampled, the last window *will* be a full window
            when:

            - the stride is the sampling rate of the data (or stride = 1 for
              sample-based configurations).&lt;br&gt;
              **Remark**: that when `include_final_window` is set to False, the last
              window (which is a full) window will not be included!
            - *(len * sampling_rate - window_size) % stride = 0*. Remark that the above
              case is a base case of this.
    approve_sparsity: bool, optional
        Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
        irregularly sampled data), by default False.
        If False and sparsity is observed, a warning is raised.

    Notes
    -----
    * This instance withholds a **read-only**-view of the data its values.

    &#34;&#34;&#34;

    # Class variables which are used by subclasses
    win_str_type: DataType
    reset_series_index_b4_segmenting: bool = False
    OUTSIDE_DATA_BOUNDS_WARNING: str = (
        &#34;Some segment indexes are outside the range of the data its index.&#34;
    )

    # Create the named tuple
    _NumpySeriesContainer = namedtuple(  # type: ignore[name-match]
        &#34;SeriesContainer&#34;, [&#34;name&#34;, &#34;values&#34;, &#34;start_indexes&#34;, &#34;end_indexes&#34;]
    )

    def __init__(
        self,
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: Optional[T],
        strides: Optional[Union[T, List[T]]] = None,
        segment_start_idxs: Optional[np.ndarray] = None,
        segment_end_idxs: Optional[np.ndarray] = None,
        start_idx: Optional[T] = None,
        end_idx: Optional[T] = None,
        func_data_type: Union[np.ndarray, pd.Series] = np.ndarray,
        window_idx: str = &#34;end&#34;,
        include_final_window: bool = False,
        approve_sparsity: bool = False,
    ):
        if strides is not None:
            strides = to_list(strides)

        # Check the passed segment indices
        if segment_start_idxs is not None and segment_end_idxs is not None:
            _check_start_end_array(segment_start_idxs, segment_end_idxs)

        if window is not None:
            assert AttributeParser.check_expected_type(
                [window] + ([] if strides is None else strides), self.win_str_type
            )

        self.window = window  # type: ignore[var-annotated]
        self.strides = strides  # type: ignore[var-annotated]

        self.window_idx = window_idx
        self.include_final_window = include_final_window
        self.approve_sparsity = approve_sparsity

        assert func_data_type in SUPPORTED_STROLL_TYPES
        self.data_type = func_data_type

        # 0. Standardize the input
        series_list: List[pd.Series] = to_series_list(data)
        self.series_dtype = AttributeParser.determine_type(series_list)
        self.series_key: Tuple[str, ...] = tuple([str(s.name) for s in series_list])

        # 1. Determine the start index
        self.start, self.end = start_idx, end_idx  # type: ignore[var-annotated]
        if self.start is None or self.end is None:
            # We always pass start_idx and end_idx from the FeatureCollection.calculate
            # Hence, this code is only useful for testing purposes
            start, end = _determine_bounds(&#34;inner&#34;, series_list)

            # update self.start &amp; self.end if it was not passed
            self.start = start if self.start is None else self.start
            self.end = end if self.end is None else self.end

        # Especially useful when the index dtype differs from the win-stride-dtype
        # e.g. -&gt; performing a int-based stroll on time-indexed data
        # Note: this is very niche and thus requires advanced knowledge
        # TODO: this code can be omitted if we remove TimeIndexSampleStridedRolling
        self._update_start_end_indices_to_stroll_type(series_list)

        # 2. Construct the index ranges
        # Either use the passed segment indices or compute the start or end times of the
        # segments. The segment indices have precedence over the stride (and window) for
        # index computation.
        if segment_start_idxs is not None or segment_end_idxs is not None:
            self.strides = None
            if segment_start_idxs is not None and segment_end_idxs is not None:
                # When both the start and end points are passed, the window does not
                # matter.
                self.window = None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = self._parse_segment_idxs(segment_end_idxs)
            elif segment_start_idxs is not None:  # segment_end_idxs is None
                np_start_times = self._parse_segment_idxs(segment_start_idxs)
                np_end_times = np_start_times + self._get_np_value(self.window)
            else:  # segment_end_idxs is not None and segment_start_idxs is None
                np_end_times = self._parse_segment_idxs(segment_end_idxs)  # type: ignore[arg-type]
                np_start_times = np_end_times - self._get_np_value(self.window)
        else:
            np_start_times = self._construct_start_idxs()
            np_end_times = np_start_times + self._get_np_value(self.window)

        # Check the numpy start and end indices
        _check_start_end_array(np_start_times, np_end_times)

        # 3. Create a new-index which will be used for DataFrame reconstruction
        # Note: the index-name of the first passed series will be re-used as index-name
        self.index = self._get_output_index(
            np_start_times, np_end_times, name=series_list[0].index.name
        )

        # 4. Store the series containers
        self.series_containers = self._construct_series_containers(
            series_list, np_start_times, np_end_times
        )

        # 5. Check the sparsity assumption
        if not self.approve_sparsity and len(self.index):
            for container in self.series_containers:
                # Warn when min != max
                if np.ptp(container.end_indexes - container.start_indexes) != 0:
                    warnings.warn(
                        f&#34;There are gaps in the sequence of the {container.name}&#34;
                        f&#34;-series!&#34;,
                        RuntimeWarning,
                    )

    def _calc_nb_segments_for_stride(self, stride: T) -&gt; int:
        &#34;&#34;&#34;Calculate the number of output items (segments) for a given single stride.&#34;&#34;&#34;
        assert self.start is not None and self.end is not None  # for mypy
        nb_feats = max((self.end - self.start - self.window) // stride + 1, 0)
        # Add 1 if there is still some data after (including) the last window its
        # start index - this is only added when `include_last_window` is True.
        nb_feats += self.include_final_window * (
            self.start + stride * nb_feats &lt;= self.end
        )
        return nb_feats

    def _get_np_start_idx_for_stride(self, stride: T) -&gt; np.ndarray:
        &#34;&#34;&#34;Compute the start index for the given single stride.&#34;&#34;&#34;
        # ---------- Efficient numpy code -------
        np_start = self._get_np_value(self.start)
        np_stride = self._get_np_value(stride)
        # Compute the start times (these remain the same for each series)
        return np.arange(
            start=np_start,
            stop=np_start + self._calc_nb_segments_for_stride(stride) * np_stride,
            step=np_stride,
        )

    def _construct_start_idxs(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Construct the start indices of the segments (for all stride values).

        To realize this, we compute the start idxs for each stride and then merge them
        together (without duplicates) in a sorted array.
        &#34;&#34;&#34;
        start_idxs = []
        for stride in self.strides:
            start_idxs += [self._get_np_start_idx_for_stride(stride)]
        # note - np.unique also sorts the array
        return np.unique(np.concatenate(start_idxs))

    def _get_output_index(
        self, start_idxs: np.ndarray, end_idxs: np.ndarray, name: str
    ) -&gt; pd.Index:
        &#34;&#34;&#34;Construct the output index.&#34;&#34;&#34;
        if self.window_idx == &#34;end&#34;:
            return pd.Index(end_idxs, name=name)
        elif self.window_idx == &#34;middle&#34;:
            return pd.Index(
                start_idxs + ((end_idxs - start_idxs) / 2),
                name=name,
            )
        elif self.window_idx == &#34;begin&#34;:
            return pd.Index(start_idxs, name=name)
        else:
            raise ValueError(
                f&#34;window index {self.window_idx} must be either of: &#34;
                &#34;[&#39;end&#39;, &#39;middle&#39;, &#39;begin&#39;]&#34;
            )

    def _construct_series_containers(
        self,
        series_list: List[pd.Series],
        np_start_times: np.ndarray,
        np_end_times: np.ndarray,
    ) -&gt; List[StridedRolling._NumpySeriesContainer]:
        series_containers: List[StridedRolling._NumpySeriesContainer] = []
        for series in series_list:
            if not self.reset_series_index_b4_segmenting:
                np_idx_times = series.index.values
            else:
                np_idx_times = np.arange(len(series))
                # note: using pd.RangeIndex instead of arange gives the same performance

            series_name = series.name
            if self.data_type is np.ndarray:  # FuncWrapper.input_type is np.ndarray
                # create a non-writeable view of the series
                series = series.values  # np.array will be stored in the SeriesContainer
                series.flags.writeable = False
            elif self.data_type is pd.Series:  # FuncWrapper.input_type is pd.Series
                # pd.Series will be stored in the SeriesContainer
                series.values.flags.writeable = False
                series.index.values.flags.writeable = False
            else:
                raise ValueError(&#34;unsupported datatype&#34;)

            series_containers.append(
                StridedRolling._NumpySeriesContainer(
                    name=series_name,
                    values=series,
                    # the slicing will be performed on [ t_start, t_end [
                    # TODO: this can maybe be optimized -&gt; further look into this
                    # np_idx_times, np_start_times, &amp; np_end_times are all sorted!
                    # as we assume &amp; check that the time index is monotonically
                    # increasing &amp; the latter 2 are created using `np.arange()`
                    start_indexes=np.searchsorted(np_idx_times, np_start_times, &#34;left&#34;),
                    end_indexes=np.searchsorted(np_idx_times, np_end_times, &#34;left&#34;),
                )
            )
        return series_containers

    def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Apply a function to the segmented series.

        Parameters
        ----------
        func : FuncWrapper
            The Callable wrapped function which will be applied.

        Returns
        -------
        pd.DataFrame
            The merged output of the function applied to every column in a
            new DataFrame. The DataFrame&#39;s column-names have the format:
                `&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;`.

        Raises
        ------
        ValueError
            If the passed ``func`` tries to adjust the data its read-only view.

        Notes
        -----
        * If ``func`` is only a callable argument, with no additional logic, this
          will only work for a one-to-one mapping, i.e., no multiple feature-output
          columns are supported for this case!&lt;br&gt;
        * If you want to calculate one-to-many, ``func`` should be
          a ``FuncWrapper`` instance and explicitly use
          the ``output_names`` attributes of its constructor.

        &#34;&#34;&#34;
        feat_names = func.output_names

        t_start = time.perf_counter()

        # --- Future work ---
        # would be nice if we could optimize this double for loop with something
        # more vectorized
        #
        # As for now we use a map to apply the function (as this evaluates its
        # expression only once, whereas a list comprehension evaluates its expression
        # every time).
        # See more why: https://stackoverflow.com/a/59838723
        out: np.ndarray
        if func.vectorized:
            # Vectorized function execution

            ## IMPL 1
            ## Results in a high memory peak as a new np.array is created (and thus no
            ## view is being used)
            # out = np.asarray(
            #         func(
            #             *[
            #                 np.array([
            #                     sc.values[sc.start_indexes[idx]: sc.end_indexes[idx]]
            #                     for idx in range(len(self.index))
            #                 ])
            #                 for sc in self.series_containers
            #             ],
            #         )
            #     )

            ## IMPL 2
            ## Is a good implementation (equivalent to the one below), will also fail in
            ## the same cases, but it does not perform clear assertions (with their
            ## accompanied clear messages).
            # out = np.asarray(
            #     func(
            #         *[
            #             _sliding_strided_window_1d(sc.values, self.window, self.stride)
            #             for sc in self.series_containers
            #         ],
            #     )
            # )

            views: List[np.ndarray] = []
            for sc in self.series_containers:
                if len(sc.start_indexes) == 0:
                    # There are no feature windows  -&gt; return empty array (see below)
                    views = []
                    break
                elif len(sc.start_indexes) == 1:
                    # There is only 1 feature window (bc no steps in the sliding window)
                    views.append(
                        np.expand_dims(
                            sc.values[sc.start_indexes[0] : sc.end_indexes[0]],
                            axis=0,
                        )
                    )
                else:
                    # There are &gt;1 feature windows (bc &gt;=1 steps in the sliding window)
                    windows = sc.end_indexes - sc.start_indexes
                    strides = sc.start_indexes[1:] - sc.start_indexes[:-1]
                    assert np.all(windows == windows[0]), (
                        &#34;Vectorized functions require same number of samples in each &#34;
                        + &#34;segmented window!&#34;
                    )
                    assert np.all(
                        strides == strides[0]
                    ), &#34;Vectorized functions require same number of samples as stride!&#34;
                    views.append(
                        _sliding_strided_window_1d(
                            sc.values[sc.start_indexes[0] :],
                            windows[0],
                            strides[0],
                            len(self.index),
                        )
                    )

            # Assign empty array as output when there is no view to apply the vectorized
            # function on (this is the case when there is at least for one series no
            # feature windows)
            out = func(*views) if len(views) &gt;= 1 else np.array([])

            out_type = type(out)
            out = np.asarray(out)
            # When multiple outputs are returned (= tuple) they should be transposed
            # when combining into an array
            out = out.T if out_type is tuple else out

        else:
            # Function execution over slices (default)
            out = np.array(
                list(
                    map(
                        func,
                        *[
                            [
                                sc.values[sc.start_indexes[idx] : sc.end_indexes[idx]]
                                for idx in range(len(self.index))
                            ]
                            for sc in self.series_containers
                        ],
                    )
                )
            )

        # Check if the function output is valid.
        # This assertion will be raised when e.g. np.max is applied vectorized without
        # specifying axis=1.
        assert out.ndim &gt; 0, &#34;Vectorized function returned only 1 (non-array) value!&#34;

        # Aggregate function output in a dictionary
        output_names = list(map(self._create_feat_col_name, feat_names))
        feat_out = _process_func_output(out, self.index, output_names, str(func))
        # Log the function execution time
        log_strides = (
            &#34;manual&#34; if self.strides is None else tuple(map(str, self.strides))
        )
        log_window = &#34;manual&#34; if self.window is None else self.window
        _log_func_execution(
            t_start, func, self.series_key, log_window, log_strides, output_names  # type: ignore[arg-type]
        )

        return pd.DataFrame(feat_out, index=self.index)

    # --------------------------------- STATIC METHODS ---------------------------------
    @staticmethod
    def _get_np_value(val: Union[np.number, pd.Timestamp, pd.Timedelta]) -&gt; np.number:
        # Convert everything to int64
        if isinstance(val, pd.Timestamp):
            return val.to_datetime64()
        elif isinstance(val, pd.Timedelta):
            return val.to_timedelta64()
        else:
            return val

    @staticmethod
    def construct_output_index(
        series_keys: Union[str, Tuple[str, ...]], feat_name: str, win_str: str
    ) -&gt; str:
        series_keys = to_tuple(series_keys)
        return f&#34;{&#39;|&#39;.join(series_keys)}__{feat_name}__w={win_str}&#34;

    # ----------------------------- OVERRIDE THESE METHODS -----------------------------
    @abstractmethod
    def _update_start_end_indices_to_stroll_type(
        self, series_list: List[pd.Series]
    ) -&gt; None:
        # NOTE: This method will only be implemented (with code != pass) in the
        # TimeIndexSampleStridedRolling
        raise NotImplementedError

    @abstractmethod
    def _parse_segment_idxs(self, segment_idxs: np.ndarray) -&gt; np.ndarray:
        &#34;&#34;&#34;Check the segment indexes array to lie between self.start and self.end and
        convert it to the correct dtype (if necessary).&#34;&#34;&#34;
        raise NotImplementedError

    @abstractmethod
    def _create_feat_col_name(self, feat_name: str) -&gt; str:
        raise NotImplementedError</code></pre>
</details>
<div class="desc"><p>Custom time-based sliding window with stride.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd><code>pd.Series</code> or <code>pd.DataFrame</code> to slide over, the index must be either
numeric or a <code>pd.DatetimeIndex</code>.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[float, pd.Timedelta]</code></dt>
<dd>Either an int, float, or <code>pd.Timedelta</code>, representing the sliding window size
in terms of the index (in case of a int or float) or the sliding window duration
(in case of <code>pd.Timedelta</code>).</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[float, pd.Timedelta, List[Union[float, pd.Timedelta]]]</code>, optional</dt>
<dd>Either a list of int, float, or <code>pd.Timedelta</code>, representing the stride sizes
in terms of the index (in case of a int or float) or the stride duration (in
case of <code>pd.Timedelta</code>). By default None.</dd>
<dt><strong><code>segment_start_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The start indices for the segmented windows. If not provided, the start indices
will be computed from the data using the passed <code>strides</code> or by using the
<code>segment_end_idxs</code> (if not none) + <code>window</code>. By default None.</dd>
<dt><strong><code>segment_end_idxs</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The end indices for the segmented windows. If not provided, the end indices will
be computed from either (1) the data using the passed <code>window</code> + <code>strides</code>
or (2) the <code>segment_start_idxs</code> + <code>window</code>, By default None.<div class="admonition note">
<p class="admonition-title">Note</p>
When you pass arrays to both <code>segment_start_idxs</code> and
<code>segment_end_idxs</code>, the corresponding index-values of these arrays will be
used as segment-ranges. As a result, the following properties must be met:<ul>
<li>both arrays should have equal length</li>
<li>all values in <code>segment_start_idxs</code> should be &lt;= <code>segment_end_idxs</code></li>
</ul>
</div>
</dd>
<dt><strong><code>start_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The start-index which will be used for each series passed to <code>data</code>. This is
especially useful if multiple <code><a title="tsflex.features.segmenter.StridedRolling" href="#tsflex.features.segmenter.StridedRolling">StridedRolling</a></code> instances are created and the
user want to ensure same (start-)indexes for each of them.</dd>
<dt><strong><code>end_idx</code></strong> :&ensp;<code>Union[float, pd.Timestamp]</code>, optional</dt>
<dd>The end-index which will be used as sliding end-limit for each series passed to
<code>data</code>.</dd>
<dt><strong><code>func_data_type</code></strong> :&ensp;<code>Union[np.array, pd.Series]</code>, optional</dt>
<dd>The data type of the stroll (either np.array or pd.Series), by default np.array.
<br><div class="admonition note">
<p class="admonition-title">Note</p>
Make sure to only set this argument to pd.Series when this is really
required, since pd.Series strided-rolling is significantly less efficient.
For a np.array it is possible to create very efficient views, but there is
no such thing as a pd.Series view. Thus, for each stroll, a new series is
created, inducing a lot of non-feature calculation of overhead.</div>
</dd>
<dt><strong><code>window_idx</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The window's index position which will be used as index for the
feature_window aggregation. Must be either of: <code>["begin", "middle", "end"]</code>, by
default "end".</dd>
<dt><strong><code>include_final_window</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>
<p>Whether the final (possibly incomplete) window should be included in the
strided-window segmentation, by default False.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The remarks below apply when <code>include_final_window</code> is set to True.
The user should be aware that the last window <em>might</em> be incomplete, i.e.;</p>
<ul>
<li>when equally sampled, the last window <em>might</em> be smaller than the
the other windows.</li>
<li>when not equally sampled, the last window <em>might</em> not include all the
data points (as the begin-time + window-size comes after the last data
point).</li>
</ul>
<p>Note, that when equally sampled, the last window <em>will</em> be a full window
when:</p>
<ul>
<li>the stride is the sampling rate of the data (or stride = 1 for
sample-based configurations).<br>
<strong>Remark</strong>: that when <code>include_final_window</code> is set to False, the last
window (which is a full) window will not be included!</li>
<li><em>(len * sampling_rate - window_size) % stride = 0</em>. Remark that the above
case is a base case of this.</li>
</ul>
</div>
</dd>
<dt><strong><code>approve_sparsity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Bool indicating whether the user acknowledges that there may be sparsity (i.e.,
irregularly sampled data), by default False.
If False and sparsity is observed, a warning is raised.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>This instance withholds a <strong>read-only</strong>-view of the data its values.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="tsflex.features.segmenter.strided_rolling.SequenceStridedRolling" href="strided_rolling.html#tsflex.features.segmenter.strided_rolling.SequenceStridedRolling">SequenceStridedRolling</a></li>
<li><a title="tsflex.features.segmenter.strided_rolling.TimeStridedRolling" href="strided_rolling.html#tsflex.features.segmenter.strided_rolling.TimeStridedRolling">TimeStridedRolling</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="tsflex.features.segmenter.StridedRolling.win_str_type"><code class="name">var <span class="ident">win_str_type</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.StridedRolling.reset_series_index_b4_segmenting"><code class="name">var <span class="ident">reset_series_index_b4_segmenting</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="tsflex.features.segmenter.StridedRolling.OUTSIDE_DATA_BOUNDS_WARNING"><code class="name">var <span class="ident">OUTSIDE_DATA_BOUNDS_WARNING</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="tsflex.features.segmenter.StridedRolling.construct_output_index"><code class="name flex">
<span>def <span class="ident">construct_output_index</span></span>(<span>series_keys, feat_name, win_str)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def construct_output_index(
    series_keys: Union[str, Tuple[str, ...]], feat_name: str, win_str: str
) -&gt; str:
    series_keys = to_tuple(series_keys)
    return f&#34;{&#39;|&#39;.join(series_keys)}__{feat_name}__w={win_str}&#34;</code></pre>
</details>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="tsflex.features.segmenter.StridedRolling.apply_func"><code class="name flex">
<span>def <span class="ident">apply_func</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_func(self, func: FuncWrapper) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Apply a function to the segmented series.

    Parameters
    ----------
    func : FuncWrapper
        The Callable wrapped function which will be applied.

    Returns
    -------
    pd.DataFrame
        The merged output of the function applied to every column in a
        new DataFrame. The DataFrame&#39;s column-names have the format:
            `&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;`.

    Raises
    ------
    ValueError
        If the passed ``func`` tries to adjust the data its read-only view.

    Notes
    -----
    * If ``func`` is only a callable argument, with no additional logic, this
      will only work for a one-to-one mapping, i.e., no multiple feature-output
      columns are supported for this case!&lt;br&gt;
    * If you want to calculate one-to-many, ``func`` should be
      a ``FuncWrapper`` instance and explicitly use
      the ``output_names`` attributes of its constructor.

    &#34;&#34;&#34;
    feat_names = func.output_names

    t_start = time.perf_counter()

    # --- Future work ---
    # would be nice if we could optimize this double for loop with something
    # more vectorized
    #
    # As for now we use a map to apply the function (as this evaluates its
    # expression only once, whereas a list comprehension evaluates its expression
    # every time).
    # See more why: https://stackoverflow.com/a/59838723
    out: np.ndarray
    if func.vectorized:
        # Vectorized function execution

        ## IMPL 1
        ## Results in a high memory peak as a new np.array is created (and thus no
        ## view is being used)
        # out = np.asarray(
        #         func(
        #             *[
        #                 np.array([
        #                     sc.values[sc.start_indexes[idx]: sc.end_indexes[idx]]
        #                     for idx in range(len(self.index))
        #                 ])
        #                 for sc in self.series_containers
        #             ],
        #         )
        #     )

        ## IMPL 2
        ## Is a good implementation (equivalent to the one below), will also fail in
        ## the same cases, but it does not perform clear assertions (with their
        ## accompanied clear messages).
        # out = np.asarray(
        #     func(
        #         *[
        #             _sliding_strided_window_1d(sc.values, self.window, self.stride)
        #             for sc in self.series_containers
        #         ],
        #     )
        # )

        views: List[np.ndarray] = []
        for sc in self.series_containers:
            if len(sc.start_indexes) == 0:
                # There are no feature windows  -&gt; return empty array (see below)
                views = []
                break
            elif len(sc.start_indexes) == 1:
                # There is only 1 feature window (bc no steps in the sliding window)
                views.append(
                    np.expand_dims(
                        sc.values[sc.start_indexes[0] : sc.end_indexes[0]],
                        axis=0,
                    )
                )
            else:
                # There are &gt;1 feature windows (bc &gt;=1 steps in the sliding window)
                windows = sc.end_indexes - sc.start_indexes
                strides = sc.start_indexes[1:] - sc.start_indexes[:-1]
                assert np.all(windows == windows[0]), (
                    &#34;Vectorized functions require same number of samples in each &#34;
                    + &#34;segmented window!&#34;
                )
                assert np.all(
                    strides == strides[0]
                ), &#34;Vectorized functions require same number of samples as stride!&#34;
                views.append(
                    _sliding_strided_window_1d(
                        sc.values[sc.start_indexes[0] :],
                        windows[0],
                        strides[0],
                        len(self.index),
                    )
                )

        # Assign empty array as output when there is no view to apply the vectorized
        # function on (this is the case when there is at least for one series no
        # feature windows)
        out = func(*views) if len(views) &gt;= 1 else np.array([])

        out_type = type(out)
        out = np.asarray(out)
        # When multiple outputs are returned (= tuple) they should be transposed
        # when combining into an array
        out = out.T if out_type is tuple else out

    else:
        # Function execution over slices (default)
        out = np.array(
            list(
                map(
                    func,
                    *[
                        [
                            sc.values[sc.start_indexes[idx] : sc.end_indexes[idx]]
                            for idx in range(len(self.index))
                        ]
                        for sc in self.series_containers
                    ],
                )
            )
        )

    # Check if the function output is valid.
    # This assertion will be raised when e.g. np.max is applied vectorized without
    # specifying axis=1.
    assert out.ndim &gt; 0, &#34;Vectorized function returned only 1 (non-array) value!&#34;

    # Aggregate function output in a dictionary
    output_names = list(map(self._create_feat_col_name, feat_names))
    feat_out = _process_func_output(out, self.index, output_names, str(func))
    # Log the function execution time
    log_strides = (
        &#34;manual&#34; if self.strides is None else tuple(map(str, self.strides))
    )
    log_window = &#34;manual&#34; if self.window is None else self.window
    _log_func_execution(
        t_start, func, self.series_key, log_window, log_strides, output_names  # type: ignore[arg-type]
    )

    return pd.DataFrame(feat_out, index=self.index)</code></pre>
</details>
<div class="desc"><p>Apply a function to the segmented series.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>FuncWrapper</code></dt>
<dd>The Callable wrapped function which will be applied.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>The merged output of the function applied to every column in a
new DataFrame. The DataFrame's column-names have the format:
<code>&lt;series_col_name(s)&gt;_&lt;feature_name&gt;__w=&lt;window&gt;</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the passed <code>func</code> tries to adjust the data its read-only view.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>If <code>func</code> is only a callable argument, with no additional logic, this
will only work for a one-to-one mapping, i.e., no multiple feature-output
columns are supported for this case!<br></li>
<li>If you want to calculate one-to-many, <code>func</code> should be
a <code>FuncWrapper</code> instance and explicitly use
the <code>output_names</code> attributes of its constructor.</li>
</ul></div>
</dd>
</dl>
</dd>
<dt id="tsflex.features.segmenter.StridedRollingFactory"><code class="flex name class">
<span>class <span class="ident">StridedRollingFactory</span></span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class StridedRollingFactory:
    &#34;&#34;&#34;Factory class for creating the appropriate StridedRolling segmenter.&#34;&#34;&#34;

    _datatype_to_stroll = {
        DataType.TIME: TimeStridedRolling,
        DataType.SEQUENCE: SequenceStridedRolling,
    }

    @staticmethod
    def get_segmenter(  # type: ignore[no-untyped-def]
        data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
        window: Union[int, float, pd.Timedelta],
        strides: Optional[List[Union[int, float, pd.Timedelta]]],
        **kwargs,
    ) -&gt; StridedRolling:
        &#34;&#34;&#34;Get the appropriate StridedRolling instance for the passed data.

        The returned instance will be determined by the data its index type

        Parameters
        ----------
        data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]
            The data to segment.
        window : Union[int, float, pd.Timedelta]
             The window size to use for the segmentation.
        strides : Union[List[Union[int, float, pd.Timedelta]], None]
            The stride(s) to use for the segmentation.
        **kwargs : dict, optional
            Additional keyword arguments, see the `StridedRolling` its documentation
            for more info.

        .. Note::
            When passing `time-based` data, but **int**-based window &amp; stride params,
            the strided rolling will be `TimeIndexSampleStridedRolling`. This class
            **assumes** that **all data series** _roughly_ have the
            **same sample frequency**, as  the windows and strides are interpreted in
            terms of **number of samples**.

        Raises
        ------
        ValueError
            When incompatible data &amp; window-stride data types are passed (e.g. time
            window-stride args on sequence data-index).

        Returns
        -------
        StridedRolling
            The constructed StridedRolling instance.

        &#34;&#34;&#34;
        data_dtype = AttributeParser.determine_type(data)
        if strides is None:
            args_dtype = AttributeParser.determine_type(window)
        else:
            args_dtype = AttributeParser.determine_type([window] + strides)

        if window is None or data_dtype.value == args_dtype.value:
            return StridedRollingFactory._datatype_to_stroll[data_dtype](
                data, window, strides, **kwargs
            )
        elif data_dtype == DataType.TIME and args_dtype == DataType.SEQUENCE:
            # Note: this is very niche and thus requires advanced knowledge
            assert isinstance(window, int)
            if strides is not None:
                assert isinstance(strides, list) and all(
                    isinstance(s, int) for s in strides
                )
            return TimeIndexSampleStridedRolling(data, window, strides, **kwargs)
        elif data_dtype == DataType.SEQUENCE and args_dtype == DataType.TIME:
            raise ValueError(&#34;Cannot segment a sequence-series with a time window&#34;)

        # This should never happen
        raise ValueError(
            f&#34;Cannot segment data of type {data_dtype} with window-stride of type {args_dtype}&#34;
        )</code></pre>
</details>
<div class="desc"><p>Factory class for creating the appropriate StridedRolling segmenter.</p></div>
<h3>Static methods</h3>
<dl>
<dt id="tsflex.features.segmenter.StridedRollingFactory.get_segmenter"><code class="name flex">
<span>def <span class="ident">get_segmenter</span></span>(<span>data, window, strides, **kwargs)</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def get_segmenter(  # type: ignore[no-untyped-def]
    data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],
    window: Union[int, float, pd.Timedelta],
    strides: Optional[List[Union[int, float, pd.Timedelta]]],
    **kwargs,
) -&gt; StridedRolling:
    &#34;&#34;&#34;Get the appropriate StridedRolling instance for the passed data.

    The returned instance will be determined by the data its index type

    Parameters
    ----------
    data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]
        The data to segment.
    window : Union[int, float, pd.Timedelta]
         The window size to use for the segmentation.
    strides : Union[List[Union[int, float, pd.Timedelta]], None]
        The stride(s) to use for the segmentation.
    **kwargs : dict, optional
        Additional keyword arguments, see the `StridedRolling` its documentation
        for more info.

    .. Note::
        When passing `time-based` data, but **int**-based window &amp; stride params,
        the strided rolling will be `TimeIndexSampleStridedRolling`. This class
        **assumes** that **all data series** _roughly_ have the
        **same sample frequency**, as  the windows and strides are interpreted in
        terms of **number of samples**.

    Raises
    ------
    ValueError
        When incompatible data &amp; window-stride data types are passed (e.g. time
        window-stride args on sequence data-index).

    Returns
    -------
    StridedRolling
        The constructed StridedRolling instance.

    &#34;&#34;&#34;
    data_dtype = AttributeParser.determine_type(data)
    if strides is None:
        args_dtype = AttributeParser.determine_type(window)
    else:
        args_dtype = AttributeParser.determine_type([window] + strides)

    if window is None or data_dtype.value == args_dtype.value:
        return StridedRollingFactory._datatype_to_stroll[data_dtype](
            data, window, strides, **kwargs
        )
    elif data_dtype == DataType.TIME and args_dtype == DataType.SEQUENCE:
        # Note: this is very niche and thus requires advanced knowledge
        assert isinstance(window, int)
        if strides is not None:
            assert isinstance(strides, list) and all(
                isinstance(s, int) for s in strides
            )
        return TimeIndexSampleStridedRolling(data, window, strides, **kwargs)
    elif data_dtype == DataType.SEQUENCE and args_dtype == DataType.TIME:
        raise ValueError(&#34;Cannot segment a sequence-series with a time window&#34;)

    # This should never happen
    raise ValueError(
        f&#34;Cannot segment data of type {data_dtype} with window-stride of type {args_dtype}&#34;
    )</code></pre>
</details>
<div class="desc"><p>Get the appropriate StridedRolling instance for the passed data.</p>
<p>The returned instance will be determined by the data its index type</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]</code></dt>
<dd>The data to segment.</dd>
<dt><strong><code>window</code></strong> :&ensp;<code>Union[int, float, pd.Timedelta]</code></dt>
<dd>The window size to use for the segmentation.</dd>
<dt><strong><code>strides</code></strong> :&ensp;<code>Union[List[Union[int, float, pd.Timedelta]], None]</code></dt>
<dd>The stride(s) to use for the segmentation.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Additional keyword arguments, see the <code><a title="tsflex.features.segmenter.StridedRolling" href="#tsflex.features.segmenter.StridedRolling">StridedRolling</a></code> its documentation
for more info.</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When passing <code>time-based</code> data, but <strong>int</strong>-based window &amp; stride params,
the strided rolling will be <code>TimeIndexSampleStridedRolling</code>. This class
<strong>assumes</strong> that <strong>all data series</strong> <em>roughly</em> have the
<strong>same sample frequency</strong>, as
the windows and strides are interpreted in
terms of <strong>number of samples</strong>.</p>
</div>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>When incompatible data &amp; window-stride data types are passed (e.g. time
window-stride args on sequence data-index).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="tsflex.features.segmenter.StridedRolling" href="#tsflex.features.segmenter.StridedRolling">StridedRolling</a></code></dt>
<dd>The constructed StridedRolling instance.</dd>
</dl></div>
</dd>
</dl>
</dd>
</dl>
</section>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</article>
<div class="sidebar_container">
<nav id="sidebar">
<div id="sidebar_content">
<header>
<div style="text-align: left; padding-top: 15px;">
<a class="homelink" rel="home" title="tsflex home" href="/tsflex/">
<img src="https://raw.githubusercontent.com/predict-idlab/tsflex/main/docs/_static/logo.png"
alt="logo should be displayed here" width="95%"></a>
</div>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="tsflex.features" href="../index.html">.features</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">tsflex.features.segmenter: API reference</a></h3>
<ul>
<li><code><a title="tsflex.features.segmenter.strided_rolling" href="strided_rolling.html">.strided_rolling</a></code></li>
<li><code><a title="tsflex.features.segmenter.strided_rolling_factory" href="strided_rolling_factory.html">.strided_rolling_factory</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="tsflex.features.segmenter.StridedRolling" href="#tsflex.features.segmenter.StridedRolling">StridedRolling</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.StridedRolling.construct_output_index" href="#tsflex.features.segmenter.StridedRolling.construct_output_index">construct_output_index</a></code></li>
<li><code><a title="tsflex.features.segmenter.StridedRolling.apply_func" href="#tsflex.features.segmenter.StridedRolling.apply_func">apply_func</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="tsflex.features.segmenter.StridedRollingFactory" href="#tsflex.features.segmenter.StridedRollingFactory">StridedRollingFactory</a></code></h4>
<ul class="">
<li><code><a title="tsflex.features.segmenter.StridedRollingFactory.get_segmenter" href="#tsflex.features.segmenter.StridedRollingFactory.get_segmenter">get_segmenter</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</nav>
</div>
</main>
<script>
const sidebar = document.querySelector("body > main > div");
const sidebar_nav = document.querySelector("body > main > div > nav");
const sidebar_content = document.getElementById("sidebar_content");
document.getElementById("index_button_button").onclick = function () {
sidebar.classList.toggle('sidebar_small');
sidebar_nav.classList.toggle('hide_content');
sidebar_content.classList.toggle('hide_content');
}
</script>
</body>
</html>