{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a906074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cd87c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example - power consumption estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa92ce",
   "metadata": {},
   "source": [
    "This notebook withholds a (minimal) data science pipeline, where we go from `RAW` data to prediction (with a confidence interval).\n",
    "\n",
    "Using 2 _open-source_ components build by `PreDiCT-IDLab`:\n",
    "- [tsflex](https://predict-idlab.github.io/tsflex/): toolkit for flexible time-series feature extraction\n",
    "- [plotly-resampler](https://predict-idlab.github.io/plotly-resampler/): interactive visualization of large sequences of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d012ea3-cce3-47eb-86f8-2e936dd690ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext memory_profiler\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "import urllib.request as urllib2\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import catboost\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import shap\n",
    "from functional import seq\n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly_resampler import FigureResampler\n",
    "from plotly_resampler.downsamplers import LTTB, EveryNthPoint\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b4c75",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dd907-f0e7-4df1-89d5-18e38e665ccc",
   "metadata": {},
   "source": [
    "These functions are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3f0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_regression_metrics(y_true, y_pred, msg):\n",
    "    print(f\"MSE  [{msg}]: \", round(mean_squared_error(y_true, y_pred), 3))\n",
    "    print(f\"MAE  [{msg}]: \", round(mean_absolute_error(y_true, y_pred), 3))\n",
    "    print(f\"MAPE [{msg}]: \", round(mean_absolute_percentage_error(y_true, y_pred), 3))\n",
    "    print(f\"R2   [{msg}]: \", round(r2_score(y_true, y_pred), 3))\n",
    "\n",
    "\n",
    "def scatter_features(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    output_name=None,\n",
    "    n_cols=5,\n",
    "    scatter_alpha=0.4,\n",
    "    save_path: str = None,\n",
    "):\n",
    "    \"\"\"Scatter plots of the features in terms of the output.\n",
    "\n",
    "    :param X: the (input) features as a pd.DataFrame.\n",
    "    :param y: the output values.\n",
    "    :param output_name: the name the output (y), will be used as ylabel for the plots.\n",
    "    :param n_cols: the number of subplot columns.\n",
    "    :param scatter_alpha: the opacity of the scattered data for all the subplots.\n",
    "    :param save_path: the path where the scatter plot should be saved.\n",
    "\n",
    "    \"\"\"\n",
    "    n_rows = math.ceil(len(X.columns) / n_cols)\n",
    "    plt.figure(figsize=(n_cols * 4.5, n_rows * 4.5))\n",
    "\n",
    "    for idx, col in enumerate(X.columns):\n",
    "        plt.subplot(n_rows, n_cols, idx + 1)\n",
    "        try:\n",
    "            plt.scatter(X[col], y, alpha=scatter_alpha)\n",
    "        except Exception:\n",
    "            print(f\"Could not plot {col}!\")\n",
    "        plt.xlabel(col)\n",
    "        if output_name and idx % n_cols == 0:\n",
    "            plt.ylabel(output_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Scatter plot saved at {save_path}!\")\n",
    "    else:\n",
    "        return plt.show()\n",
    "\n",
    "\n",
    "def plot_learning_curve(\n",
    "    estimator,\n",
    "    title: str,\n",
    "    X,\n",
    "    y,\n",
    "    ylim=None,\n",
    "    cv: int = None,\n",
    "    n_jobs: int = None,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring=None,\n",
    "):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    borrowed from: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    scoring : str or callable, optional (default=None)\n",
    "        Scoring method for the model.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring\n",
    "    )\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    plt.plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "    plt.plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7bc845-1c78-415d-96bf-9658f4f62e96",
   "metadata": {},
   "source": [
    "# 1. loading in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798d3fe",
   "metadata": {},
   "source": [
    "This example uses the pulbic UCI [power consumption](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption) dataset.\n",
    "\n",
    "This dataset withholds measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528a337e-5492-4e2f-9c57-7506d4a5bc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-05-14 10:23:00</th>\n",
       "      <td>2.138</td>\n",
       "      <td>0.3</td>\n",
       "      <td>237.419998</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-14 05:39:00</th>\n",
       "      <td>2.288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.610001</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-21 20:22:00</th>\n",
       "      <td>3.546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.899994</td>\n",
       "      <td>14.8</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "timestamp                                                                     \n",
       "2009-05-14 10:23:00                2.138                    0.3  237.419998   \n",
       "2007-01-14 05:39:00                2.288                    0.0  240.610001   \n",
       "2009-06-21 20:22:00                3.546                    0.0  237.899994   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "timestamp                                                               \n",
       "2009-05-14 10:23:00               9.8             0.0             1.0   \n",
       "2007-01-14 05:39:00               9.4             0.0             0.0   \n",
       "2009-06-21 20:22:00              14.8            37.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "timestamp                            \n",
       "2009-05-14 10:23:00            17.0  \n",
       "2007-01-14 05:39:00             0.0  \n",
       "2009-06-21 20:22:00            17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Global_active_power    float32\n",
      " 1   Global_reactive_power  float32\n",
      " 2   Voltage                float32\n",
      " 3   Global_intensity       float32\n",
      " 4   Sub_metering_1         float32\n",
      " 5   Sub_metering_2         float32\n",
      " 6   Sub_metering_3         float32\n",
      "dtypes: float32(7)\n",
      "memory usage: 71.2 MB\n"
     ]
    }
   ],
   "source": [
    "zip_url: str = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip\"\n",
    "zipped_file_name: str = \"household_power_consumption.txt\"\n",
    "\n",
    "if False:\n",
    "    df_power_consumption: pd.DataFrame = pd.read_csv(\n",
    "        ZipFile(BytesIO(urllib2.urlopen(zip_url).read())).open(zipped_file_name),\n",
    "        sep=\";\",\n",
    "        parse_dates={\"timestamp\": [\"Date\", \"Time\"]},\n",
    "        infer_datetime_format=True,\n",
    "        low_memory=False,\n",
    "        na_values=[\"nan\", \"?\"],\n",
    "        index_col=\"timestamp\",\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "    df_power_consumption.to_parquet(\"df_power_consumption.parquet\")\n",
    "else:\n",
    "    df_power_consumption = pd.read_parquet(\"df_power_consumption.parquet\")\n",
    "\n",
    "display(df_power_consumption.sample(3))\n",
    "print(\"-\" * 80)\n",
    "df_power_consumption.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6491d-8c31-4bdb-af1a-655b253b0066",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caba702",
   "metadata": {},
   "source": [
    "**first step**: Reading the [dataset description](https://archive.ics.uci.edu/ml/datasets/Individual+household+electric+power+consumption) (or gather all information about the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b5b274",
   "metadata": {},
   "source": [
    "## 2.1 Summary of the data-properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cc9ca-cc1e-4c2f-a12d-388a8f5b169f",
   "metadata": {},
   "source": [
    "**global variables**:\n",
    "* `global_active_power`: household global **minute averaged** active power (kilowatt)\n",
    "* `global_reactive_power`: household global **minute averaged** reactive power (kilowatt)\n",
    "* `global_intensity`: household global **minute averaged** current (ampere)\n",
    "* `voltage`: minute-averaged voltage (volt)\n",
    "\n",
    "**sub meterings**:\n",
    "* `sub_metering_1`: **kitchen** - dishwasher & microwave - (in watt-hour of **active energy**)\n",
    "* `sub_metering_2`: **laundry room** - washing maching, tumble drier, refrigerator & light (in watt-hour of **active energy**)\n",
    "* `sub_metering_3`: electric water-heater & air conditioner (in watt-hour of **active energy**)\n",
    "\n",
    "\n",
    "As the user is only billed for the **active power**, we will use this variable as target."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac84897e",
   "metadata": {},
   "source": [
    "## 2.2 `Pandas` data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb1bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows=2,075,259\tcols=7\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.839996</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630005</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.289993</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "timestamp                                                                     \n",
       "2006-12-16 17:24:00                4.216                  0.418  234.839996   \n",
       "2006-12-16 17:25:00                5.360                  0.436  233.630005   \n",
       "2006-12-16 17:26:00                5.374                  0.498  233.289993   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "timestamp                                                               \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "timestamp                            \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:00:00</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.820007</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:01:00</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.699997</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26 21:02:00</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>239.550003</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power     Voltage  \\\n",
       "timestamp                                                                     \n",
       "2010-11-26 21:00:00                0.938                    0.0  239.820007   \n",
       "2010-11-26 21:01:00                0.934                    0.0  239.699997   \n",
       "2010-11-26 21:02:00                0.932                    0.0  239.550003   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "timestamp                                                               \n",
       "2010-11-26 21:00:00               3.8             0.0             0.0   \n",
       "2010-11-26 21:01:00               3.8             0.0             0.0   \n",
       "2010-11-26 21:02:00               3.8             0.0             0.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "timestamp                            \n",
       "2010-11-26 21:00:00             0.0  \n",
       "2010-11-26 21:01:00             0.0  \n",
       "2010-11-26 21:02:00             0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"rows={df_power_consumption.shape[0]:,}\\tcols={df_power_consumption.shape[1]:,}\")\n",
    "print(\"-\" * 100)\n",
    "display(df_power_consumption.head(3))\n",
    "print(\"-\" * 100)\n",
    "display(df_power_consumption.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f3d9e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('1441 days 03:38:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power_consumption.index[-1] - df_power_consumption.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c18965d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 days 00:01:00    2075258\n",
       "Name: timestamp, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so the data is actually regularly sampled\n",
    "df_power_consumption.index.to_series().diff().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40acec8",
   "metadata": {},
   "source": [
    "The data spans ~4 years; and is **regularly sampled**; Each minute, there is a new observation for each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5039c919-3d3b-4ecb-b948-e35ce9068b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN sum:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Global_active_power      25979\n",
       "Global_reactive_power    25979\n",
       "Voltage                  25979\n",
       "Global_intensity         25979\n",
       "Sub_metering_1           25979\n",
       "Sub_metering_2           25979\n",
       "Sub_metering_3           25979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It appears we have some NaN's (not a numbers) in the data.\n",
    "print(\"NaN sum:\")\n",
    "df_power_consumption.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841a3f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2049280\n",
       "7      25979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power_consumption.isna().sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87621a2",
   "metadata": {},
   "source": [
    "The check above confirms that the `NaN` for each property occurs at the same time -> fair to assume their just is no data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e8da78",
   "metadata": {},
   "source": [
    "## 2.3 Processing based on data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236d8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM now on -> we drop the nan's\n",
    "df_power_consumption = df_power_consumption.dropna(how=\"all\", axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8273b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 days 00:01:00    2049208\n",
       "0 days 00:02:00         38\n",
       "0 days 00:03:00         14\n",
       "0 days 00:04:00          2\n",
       "0 days 00:39:00          1\n",
       "5 days 00:27:00          1\n",
       "1 days 09:48:00          1\n",
       "2 days 04:10:00          1\n",
       "0 days 14:52:00          1\n",
       "0 days 00:05:00          1\n",
       "2 days 07:06:00          1\n",
       "0 days 00:25:00          1\n",
       "0 days 00:07:00          1\n",
       "0 days 01:11:00          1\n",
       "0 days 00:44:00          1\n",
       "0 days 00:22:00          1\n",
       "0 days 00:48:00          1\n",
       "0 days 01:24:00          1\n",
       "0 days 00:34:00          1\n",
       "2 days 14:04:00          1\n",
       "3 days 15:18:00          1\n",
       "Name: timestamp, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power_consumption.index.to_series().diff().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bc491c",
   "metadata": {},
   "source": [
    "## 2.4 Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcb1d382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "      <td>2049280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>240.84</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3.24</td>\n",
       "      <td>4.44</td>\n",
       "      <td>6.15</td>\n",
       "      <td>5.82</td>\n",
       "      <td>8.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.05</td>\n",
       "      <td>238.99</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>241.01</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.53</td>\n",
       "      <td>0.19</td>\n",
       "      <td>242.89</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.12</td>\n",
       "      <td>1.39</td>\n",
       "      <td>254.15</td>\n",
       "      <td>48.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Global_active_power Global_reactive_power    Voltage Global_intensity  \\\n",
       "count           2049280.0             2049280.0  2049280.0        2049280.0   \n",
       "mean                 1.09                  0.12     240.84             4.63   \n",
       "std                  1.06                  0.11       3.24             4.44   \n",
       "min                  0.08                   0.0      223.2              0.2   \n",
       "25%                  0.31                  0.05     238.99              1.4   \n",
       "50%                   0.6                   0.1     241.01              2.6   \n",
       "75%                  1.53                  0.19     242.89              6.4   \n",
       "max                 11.12                  1.39     254.15             48.4   \n",
       "\n",
       "      Sub_metering_1 Sub_metering_2 Sub_metering_3  \n",
       "count      2049280.0      2049280.0      2049280.0  \n",
       "mean            1.12            1.3           6.46  \n",
       "std             6.15           5.82           8.44  \n",
       "min              0.0            0.0            0.0  \n",
       "25%              0.0            0.0            0.0  \n",
       "50%              0.0            0.0            1.0  \n",
       "75%              0.0            1.0           17.0  \n",
       "max             88.0           80.0           31.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_power_consumption.describe().round(2).astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b8bfff-767c-4e4d-8668-751cd8799019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bfc15_row0_col0, #T_bfc15_row0_col1, #T_bfc15_row0_col2, #T_bfc15_row0_col3, #T_bfc15_row0_col4, #T_bfc15_row0_col5, #T_bfc15_row0_col6, #T_bfc15_row1_col1, #T_bfc15_row1_col2, #T_bfc15_row1_col3, #T_bfc15_row1_col4, #T_bfc15_row1_col5, #T_bfc15_row1_col6, #T_bfc15_row2_col2, #T_bfc15_row2_col3, #T_bfc15_row2_col4, #T_bfc15_row2_col5, #T_bfc15_row2_col6, #T_bfc15_row3_col3, #T_bfc15_row3_col4, #T_bfc15_row3_col5, #T_bfc15_row3_col6, #T_bfc15_row4_col4, #T_bfc15_row4_col5, #T_bfc15_row4_col6, #T_bfc15_row5_col5, #T_bfc15_row5_col6, #T_bfc15_row6_col6 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row1_col0 {\n",
       "  background-color: #d4dbe6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row2_col0 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row2_col1 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row3_col0 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row3_col1 {\n",
       "  background-color: #d7dce3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row3_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row4_col0 {\n",
       "  background-color: #f5c1a9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row4_col1 {\n",
       "  background-color: #bad0f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row4_col2 {\n",
       "  background-color: #6b8df0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row4_col3 {\n",
       "  background-color: #f5c0a7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row5_col0 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row5_col1 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row5_col2 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row5_col3 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row5_col4 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row6_col0 {\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row6_col1 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row6_col2 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bfc15_row6_col3 {\n",
       "  background-color: #f59f80;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row6_col4 {\n",
       "  background-color: #b5cdfa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bfc15_row6_col5 {\n",
       "  background-color: #afcafc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bfc15_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Global_active_power</th>\n",
       "      <th class=\"col_heading level0 col1\" >Global_reactive_power</th>\n",
       "      <th class=\"col_heading level0 col2\" >Voltage</th>\n",
       "      <th class=\"col_heading level0 col3\" >Global_intensity</th>\n",
       "      <th class=\"col_heading level0 col4\" >Sub_metering_1</th>\n",
       "      <th class=\"col_heading level0 col5\" >Sub_metering_2</th>\n",
       "      <th class=\"col_heading level0 col6\" >Sub_metering_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row0\" class=\"row_heading level0 row0\" >Global_active_power</th>\n",
       "      <td id=\"T_bfc15_row0_col0\" class=\"data row0 col0\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col1\" class=\"data row0 col1\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col2\" class=\"data row0 col2\" >-0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col3\" class=\"data row0 col3\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col4\" class=\"data row0 col4\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col5\" class=\"data row0 col5\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row0_col6\" class=\"data row0 col6\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row1\" class=\"row_heading level0 row1\" >Global_reactive_power</th>\n",
       "      <td id=\"T_bfc15_row1_col0\" class=\"data row1 col0\" >0.247</td>\n",
       "      <td id=\"T_bfc15_row1_col1\" class=\"data row1 col1\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row1_col2\" class=\"data row1 col2\" >-0.000</td>\n",
       "      <td id=\"T_bfc15_row1_col3\" class=\"data row1 col3\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row1_col4\" class=\"data row1 col4\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row1_col5\" class=\"data row1 col5\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row1_col6\" class=\"data row1 col6\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row2\" class=\"row_heading level0 row2\" >Voltage</th>\n",
       "      <td id=\"T_bfc15_row2_col0\" class=\"data row2 col0\" >-0.400</td>\n",
       "      <td id=\"T_bfc15_row2_col1\" class=\"data row2 col1\" >-0.112</td>\n",
       "      <td id=\"T_bfc15_row2_col2\" class=\"data row2 col2\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row2_col3\" class=\"data row2 col3\" >-0.000</td>\n",
       "      <td id=\"T_bfc15_row2_col4\" class=\"data row2 col4\" >-0.000</td>\n",
       "      <td id=\"T_bfc15_row2_col5\" class=\"data row2 col5\" >-0.000</td>\n",
       "      <td id=\"T_bfc15_row2_col6\" class=\"data row2 col6\" >-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row3\" class=\"row_heading level0 row3\" >Global_intensity</th>\n",
       "      <td id=\"T_bfc15_row3_col0\" class=\"data row3 col0\" >0.999</td>\n",
       "      <td id=\"T_bfc15_row3_col1\" class=\"data row3 col1\" >0.266</td>\n",
       "      <td id=\"T_bfc15_row3_col2\" class=\"data row3 col2\" >-0.411</td>\n",
       "      <td id=\"T_bfc15_row3_col3\" class=\"data row3 col3\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row3_col4\" class=\"data row3 col4\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row3_col5\" class=\"data row3 col5\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row3_col6\" class=\"data row3 col6\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row4\" class=\"row_heading level0 row4\" >Sub_metering_1</th>\n",
       "      <td id=\"T_bfc15_row4_col0\" class=\"data row4 col0\" >0.484</td>\n",
       "      <td id=\"T_bfc15_row4_col1\" class=\"data row4 col1\" >0.123</td>\n",
       "      <td id=\"T_bfc15_row4_col2\" class=\"data row4 col2\" >-0.196</td>\n",
       "      <td id=\"T_bfc15_row4_col3\" class=\"data row4 col3\" >0.489</td>\n",
       "      <td id=\"T_bfc15_row4_col4\" class=\"data row4 col4\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row4_col5\" class=\"data row4 col5\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row4_col6\" class=\"data row4 col6\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row5\" class=\"row_heading level0 row5\" >Sub_metering_2</th>\n",
       "      <td id=\"T_bfc15_row5_col0\" class=\"data row5 col0\" >0.435</td>\n",
       "      <td id=\"T_bfc15_row5_col1\" class=\"data row5 col1\" >0.139</td>\n",
       "      <td id=\"T_bfc15_row5_col2\" class=\"data row5 col2\" >-0.167</td>\n",
       "      <td id=\"T_bfc15_row5_col3\" class=\"data row5 col3\" >0.440</td>\n",
       "      <td id=\"T_bfc15_row5_col4\" class=\"data row5 col4\" >0.055</td>\n",
       "      <td id=\"T_bfc15_row5_col5\" class=\"data row5 col5\" >0.000</td>\n",
       "      <td id=\"T_bfc15_row5_col6\" class=\"data row5 col6\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bfc15_level0_row6\" class=\"row_heading level0 row6\" >Sub_metering_3</th>\n",
       "      <td id=\"T_bfc15_row6_col0\" class=\"data row6 col0\" >0.639</td>\n",
       "      <td id=\"T_bfc15_row6_col1\" class=\"data row6 col1\" >0.090</td>\n",
       "      <td id=\"T_bfc15_row6_col2\" class=\"data row6 col2\" >-0.268</td>\n",
       "      <td id=\"T_bfc15_row6_col3\" class=\"data row6 col3\" >0.627</td>\n",
       "      <td id=\"T_bfc15_row6_col4\" class=\"data row6 col4\" >0.103</td>\n",
       "      <td id=\"T_bfc15_row6_col5\" class=\"data row6 col5\" >0.081</td>\n",
       "      <td id=\"T_bfc15_row6_col6\" class=\"data row6 col6\" >0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f7c247b3970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_power_consumption.corr() * np.tril(\n",
    "    np.ones(tuple([len(df_power_consumption.columns)] * 2)), k=-1\n",
    ")\n",
    "pd.set_option(\"precision\", 3)\n",
    "corr.style.background_gradient(cmap=\"coolwarm\", axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d962b0",
   "metadata": {},
   "source": [
    "Some basic checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2448af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAP - intensity corr:         (0.9988886002045057, 0.0)\n",
      "GAP - power-estimation corr:  (0.9990928075842106, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "power_estimation = df_power_consumption.Global_intensity * df_power_consumption.Voltage\n",
    "\n",
    "print(\n",
    "    \"GAP - intensity corr:        \",\n",
    "    ss.pearsonr(\n",
    "        df_power_consumption.Global_active_power, df_power_consumption.Global_intensity\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    \"GAP - power-estimation corr: \",\n",
    "    ss.pearsonr(df_power_consumption.Global_active_power, power_estimation),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e00063",
   "metadata": {},
   "source": [
    "## 2.5 Raw data visualization using `plotly-resampler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2127b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the nan's\n",
    "df_power_consumption = df_power_consumption.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702a6a33",
   "metadata": {},
   "source": [
    "By using plotly-resampler, we are able to visualize the whole raw dataset :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c73f4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "fig = FigureResampler(\n",
    "    make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        specs=[[{\"secondary_y\": True}], [{}], [{\"secondary_y\": True}]],\n",
    "        subplot_titles=[\"Globals\", \"Voltage\", \"Sub metering\"],\n",
    "    ),\n",
    "    default_n_shown_samples=1000,\n",
    "    default_downsampler=LTTB(interleave_gaps=True),\n",
    ")\n",
    "\n",
    "for c, row, visible, secondary_y in [\n",
    "    (\"Global_active_power\", 1, 1, 0),\n",
    "    (\"Global_intensity\", 1, \"legendonly\", 1),\n",
    "    (\"Global_reactive_power\", 1, \"legendonly\", 0),\n",
    "    (\"Voltage\", 2, 1, 0),\n",
    "    (\"Sub_metering_1\", 3, 1, 0),\n",
    "    (\"Sub_metering_2\", 3, 1, 0),\n",
    "    (\"Sub_metering_3\", 3, 1, 0),\n",
    "]:\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=c, visible=visible),\n",
    "        hf_x=df_power_consumption.index,\n",
    "        hf_y=df_power_consumption[c],\n",
    "        secondary_y=secondary_y,\n",
    "        row=row,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "\n",
    "# add a shaded weekend region on the lowest row\n",
    "datelist = pd.date_range(\n",
    "    df_power_consumption.index[0].date(), df_power_consumption.index[-1], freq=\"D\"\n",
    ")\n",
    "weekend = datelist.weekday.isin([5, 6]).astype(int)\n",
    "fig.add_trace(\n",
    "    go.Scattergl(\n",
    "        line_shape=\"hv\",\n",
    "        name=\"Weekend\",\n",
    "        line_color=\"rgba(0,0,0,0)\",\n",
    "        fillcolor=\"rgba(99, 110, 250, 0.15)\",\n",
    "        fill=\"tozeroy\",\n",
    "    ),\n",
    "    hf_x=datelist,\n",
    "    hf_y=weekend,\n",
    "    limit_to_view=True,\n",
    "    max_n_samples=len(weekend),\n",
    "    secondary_y=True,\n",
    "    row=3,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_layout(height=800)\n",
    "fig.show_dash(mode=\"external\", port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b35f10",
   "metadata": {},
   "source": [
    "# 3. Define the objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a223f-6911-4218-a05c-30f72f59b67e",
   "metadata": {},
   "source": [
    "The objective is:\n",
    "> **forecast** the **average** `Global active power` (GAP)\n",
    "\n",
    "\n",
    "After a requirement meeting with the client:\n",
    "\n",
    "> He/she wants to know:\n",
    "* the **average** power-consumption for **15 minutes**, and \n",
    "* this 3 minutes in advance for the next 15-minutes period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7aebbd-1865-4d39-ae20-1a59ba4a61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our client wants to know the average power consumption per 15 minutes and this\n",
    "# 5 minutes in advance for the next 15-minute period\n",
    "avg_window_min = 15\n",
    "shift_min = -(3 + avg_window_min)\n",
    "\n",
    "avg_col = f\"GAP_avg{avg_window_min}min\"\n",
    "target_col = f\"{avg_col}_shift{shift_min}min\"\n",
    "\n",
    "# create the target by (1) calculating the average and (2) shifting the data so we will forecast\n",
    "df_power_consumption[avg_col] = df_power_consumption.rolling(\n",
    "    avg_window_min, center=True\n",
    ")[\"Global_active_power\"].aggregate(np.nanmean)\n",
    "df_power_consumption[target_col] = df_power_consumption[avg_col].shift(shift_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d2527",
   "metadata": {},
   "source": [
    " ###  Perform visual inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1b350a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/git/gIDLaB/tsflex/venv/lib/python3.8/site-packages/jupyter_dash/jupyter_app.py:139: UserWarning:\n",
      "\n",
      "The 'environ['werkzeug.server.shutdown']' function is deprecated and will be removed in Werkzeug 2.1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fig = FigureResampler(\n",
    "    make_subplots(rows=1, cols=1, shared_xaxes=True),\n",
    "    default_downsampler=LTTB(interleave_gaps=True),\n",
    ")\n",
    "\n",
    "for c, row, visible in [\n",
    "    (\"Global_active_power\", 1, 1),\n",
    "    (target_col, 1, \"legendonly\"),\n",
    "    (avg_col, 1, \"legendonly\"),\n",
    "]:\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=c, visible=visible),\n",
    "        hf_x=df_power_consumption.index,\n",
    "        hf_y=df_power_consumption[c],\n",
    "        row=row,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.update_layout(height=400)\n",
    "fig.show_dash(mode=\"external\", port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d357a6-bf82-4bec-9fac-ff50a7f7d80e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d97733-846b-4d3f-97e8-c2698f5551f8",
   "metadata": {},
   "source": [
    "## 4.1 Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5f264fd-c547-4475-99de-391c0f9a1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_col = \"time\"\n",
    "train_columns = [f\"Sub_metering_{i}\" for i in range(1, 4)] + [\n",
    "    time_col,\n",
    "    \"Global_active_power\",\n",
    "    \"Global_reactive_power\",\n",
    "]\n",
    "target_col = target_col\n",
    "\n",
    "# The percentage of data used for testing\n",
    "test_pct = 0.2\n",
    "day_margin = 3\n",
    "\n",
    "# add the timestamp col\n",
    "df_power_consumption[time_col] = df_power_consumption.index\n",
    "\n",
    "# Temporal split: Use the last test_pct of the data as test_data\n",
    "df_train = df_power_consumption[: -int(len(df_power_consumption) * test_pct)].copy()\n",
    "X_train, y_train = df_train[train_columns], df_train[target_col]\n",
    "\n",
    "df_test = df_power_consumption[df_train.index[-1] + pd.Timedelta(days=day_margin):]\n",
    "X_test, y_test = df_test[train_columns], df_test[target_col]\n",
    "\n",
    "X_test.to_parquet(\"X_test.parquet\")\n",
    "y_test.to_frame().to_parquet(\"y_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3558302-1cfb-4e26-8860-23ba725ff71e",
   "metadata": {},
   "source": [
    "## 4.2 Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f35e44-053e-4f47-978b-3b83f7599961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "import scipy.stats as ss\n",
    "from tsflex.chunking import chunk_data\n",
    "from tsflex.features import FeatureCollection, MultipleFeatureDescriptors\n",
    "from tsflex.features.utils import make_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a98df-3467-48ca-8172-bc83e3540cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# some feature functions\n",
    "def slope(x):\n",
    "    return (x[-1] - x[0]) / x[0] if x[0] else 0\n",
    "\n",
    "\n",
    "def abs_diff_mean(x):\n",
    "    return np.mean(np.abs(x[1:] - x[:-1])) if len(x) > 1 else 0\n",
    "\n",
    "\n",
    "def diff_std(x):\n",
    "    return np.std(x[1:] - x[:-1]) if len(x) > 1 else 0\n",
    "\n",
    "\n",
    "# time based features\n",
    "def time_float(x) -> float:\n",
    "    x_ = pd.Timestamp(x[-1])\n",
    "    return np.float32(x_.hour + x_.minute / 60)\n",
    "\n",
    "\n",
    "def day_of_week(x) -> int:\n",
    "    return pd.Timestamp(x[-1]).day_of_week\n",
    "\n",
    "\n",
    "def is_holiday(x) -> bool:\n",
    "    return pd.Timestamp(x[-1]) in holidays.France()\n",
    "\n",
    "\n",
    "def yesterday_holiday(x) -> bool:\n",
    "    return (pd.Timestamp(x[-1]) - pd.Timedelta(days=1)) in holidays.France()\n",
    "\n",
    "\n",
    "def tomorrow_holiday(x) -> bool:\n",
    "    return (pd.Timestamp(x[-1]) + pd.Timedelta(days=1)) in holidays.France()\n",
    "\n",
    "\n",
    "funcs = [\n",
    "    make_robust(f)\n",
    "    for f in [np.min, np.max, np.std, np.mean, slope, ss.skew, abs_diff_mean, diff_std, sum]\n",
    "]\n",
    "time_funcs = [\n",
    "    make_robust(f)\n",
    "    for f in [time_float, day_of_week, is_holiday, yesterday_holiday, tomorrow_holiday]\n",
    "]\n",
    "\n",
    "# Create the feature collection\n",
    "fc = FeatureCollection(\n",
    "    feature_descriptors=[\n",
    "        MultipleFeatureDescriptors(\n",
    "            functions=funcs,\n",
    "            series_names=list(set(train_columns).difference({time_col})),\n",
    "            windows=[\"15min\", \"30min\", \"1h\", \"6h\", \"1d\"],\n",
    "            strides=\"15min\",\n",
    "        ),\n",
    "        MultipleFeatureDescriptors(\n",
    "            functions=time_funcs,\n",
    "            series_names=time_col,\n",
    "            windows=[\"15min\"],\n",
    "            strides=\"15min\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cac5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73955641-f7d3-4178-b8ce-ee94306ca606",
   "metadata": {},
   "source": [
    "### Chunking train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7cb1eb",
   "metadata": {},
   "source": [
    "As shown in the visualizations, there were gaps in the train-data, by calling <br>\n",
    "`tsflex.chunk_data`, we:\n",
    "* omit these gaps\n",
    "* chunk the data in duration-based chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb9cfe-09e7-42fc-b2ba-53e96e914af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# chunk the data in blocks of `max_chunk_dur`\n",
    "# also omits the gaps :)\n",
    "chunks = chunk_data(\n",
    "    data=df_train,\n",
    "    max_chunk_dur=\"365 days\",\n",
    "    chunk_range_margin=\"10 min\",\n",
    "    sub_chunk_overlap=\"15min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cabee-bb68-4d0f-8f8c-87949f43c73c",
   "metadata": {},
   "source": [
    "we will now use these yearly chunks to extract the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0af4d-143c-4f16-afa9-a7c28df75547",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "if False:\n",
    "    df_train_feats = pd.concat(\n",
    "        [\n",
    "            fc.calculate(\n",
    "                chunk,\n",
    "                show_progress=True,\n",
    "                return_df=True,\n",
    "                approve_sparsity=True,\n",
    "                n_jobs=None,\n",
    "            )\n",
    "            for chunk in chunks\n",
    "        ],\n",
    "        copy=False,\n",
    "    )\n",
    "    df_train_feats.to_parquet(\"df_train_feats_unprocessed.parquet\")\n",
    "else:\n",
    "    df_train_feats = pd.read_parquet(\"df_train_feats_unprocessed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a06f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99c290",
   "metadata": {},
   "source": [
    "### Process extracted features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2509bb6",
   "metadata": {},
   "source": [
    "We will use `tsflex.propressing` to estimate to shift the previous feature columns whom have a window-size of `15 min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c4108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsflex.processing import SeriesPipeline, SeriesProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_series(s: pd.Series, shift=1):\n",
    "    return s.shift(shift).rename(f\"{s.name}_shift{shift}\")\n",
    "\n",
    "\n",
    "sp = SeriesPipeline(\n",
    "    processors=[\n",
    "        SeriesProcessor(\n",
    "            shift_series,\n",
    "            series_names=seq(df_train_feats.columns)\n",
    "            .filter(lambda x: \"w=15m\" in x and time_col not in x)\n",
    "            .to_list(),\n",
    "            shift=1,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be387195-2079-479c-a7cc-e8bdefa73506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_feats_p = sp.process(df_train_feats, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b1e29-0387-4bf2-a8e5-e8385c46c162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure that there are no duplicate indices\n",
    "print(df_train_feats_p.shape)\n",
    "df_train_feats_p = df_train_feats_p[~df_train_feats_p.index.duplicated()]\n",
    "print(df_train_feats_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2747077-cd2d-48b1-991e-4e28aeda39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = set(df_train_feats_p.columns).difference(y_train.name)\n",
    "df_train = df_train_feats_p.join(y_train)\n",
    "\n",
    "# drop the observations of which we don't have the target\n",
    "df_train = df_train.dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918804c7",
   "metadata": {},
   "source": [
    "### Put the whole feature construction process in a method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f84681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method uses the above defined feature collection to calculate features\n",
    "# aftwards it applies a seriespipeline transformations to the constructed feats\n",
    "def construct_feats(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.concat(\n",
    "        [\n",
    "            sp.process(\n",
    "                fc.calculate(\n",
    "                    c, show_progress=True, return_df=True, approve_sparsity=True\n",
    "                ),\n",
    "                return_df=True,\n",
    "            )\n",
    "            for c in chunk_data(data=data, chunk_range_margin=\"10 min\")\n",
    "        ],\n",
    "        axis=0,\n",
    "        copy=False,\n",
    "    )[selected_cols].dropna(how=\"any\", axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34021db3",
   "metadata": {},
   "source": [
    "## 4.3 Feature visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759cba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1_000\n",
    "vis_data = df_train.iloc[np.random.randint(0, len(df_train), N)]\n",
    "\n",
    "scatter_features(vis_data[selected_cols], vis_data[y_train.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434c38e",
   "metadata": {},
   "source": [
    "## 4.4 Demo: Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30c4abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time-based cross validation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "stride_min = 15\n",
    "gap_days = 3\n",
    "tscv = TimeSeriesSplit(n_splits=3, gap=int((60 / stride_min) * 24 * gap_days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PowerTransformer\n",
    "# from sklearn.linear_model import BayesianRidge, HuberRegressor\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "# pipe = Pipeline([('scaler', PowerTransformer()), ('reg', HuberRegressor())])\n",
    "# plot_learning_curve(\n",
    "#     pipe, \"learning curve\", df_train[selected_cols], df_train[y_train.name], cv=tscv\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03208964",
   "metadata": {},
   "source": [
    "## 4.5 Catboost-regression - investigating different metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4dc41",
   "metadata": {},
   "source": [
    "The image below gives an overview of the most common regression losses:<br>\n",
    "![overview losses](https://miro.medium.com/max/640/1*eH-5v54TH2Lmo1hWrjQNjA.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f081df-715d-41cf-bad8-495ae009313d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: should be evaluated by using CV and then select the one which suits your purpose\n",
    "# the best (or stack the predictions of the models)\n",
    "mape_pipe = catboost.CatBoostRegressor(verbose=250, loss_function=\"MAPE\")\n",
    "mape_pipe.fit(df_train[selected_cols], df_train[y_train.name])\n",
    "print(\"-\" * 100)\n",
    "rmse_pipe = catboost.CatBoostRegressor(verbose=250, loss_function=\"RMSE\")\n",
    "rmse_pipe.fit(df_train[selected_cols], df_train[y_train.name])\n",
    "print(\"-\" * 100)\n",
    "mae_pipe = catboost.CatBoostRegressor(verbose=250, loss_function=\"MAE\")\n",
    "mae_pipe.fit(df_train[selected_cols], df_train[y_train.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f785da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pipe in [(\"MAPE\", mape_pipe), (\"RMSE\", rmse_pipe), (\"MAE\", mae_pipe)]:\n",
    "    train_predictions = pd.Series(\n",
    "        pipe.predict(df_train[selected_cols]), index=df_train.index, name=\"predictions\"\n",
    "    )\n",
    "    df_preds = train_predictions.to_frame().join(y_train).dropna(how=\"any\")\n",
    "    print_regression_metrics(\n",
    "        df_preds[target_col], df_preds.predictions, f\"TRAIN-{name}\"\n",
    "    )\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pipe in [(\"MAPE\", mape_pipe), (\"RMSE\", rmse_pipe), (\"MAE\", mae_pipe)]:\n",
    "    train_predictions = pd.Series(\n",
    "        pipe.predict(df_train[selected_cols]), index=df_train.index, name=\"predictions\"\n",
    "    )\n",
    "    df_preds = train_predictions.to_frame().join(y_train).dropna(how=\"any\")\n",
    "    print_regression_metrics(\n",
    "        df_preds[target_col], df_preds.predictions, f\"TRAIN-{name}\"\n",
    "    )\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats = construct_feats(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, pipe in [(\"MAPE\", mape_pipe), (\"RMSE\", rmse_pipe), (\"MAE\", mae_pipe)]:\n",
    "    test_predictions = pd.Series(\n",
    "        pipe.predict(test_feats), index=test_feats.index\n",
    "    ).rename(\"predictions\")\n",
    "    df_test_preds = test_predictions.to_frame().join(y_test).dropna(how=\"any\")\n",
    "    print_regression_metrics(\n",
    "        df_test_preds[target_col], df_test_preds.predictions, f\"TEST-{name}\"\n",
    "    )\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf6915",
   "metadata": {},
   "source": [
    "### Visualization of the differently trained predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureResampler(go.Figure(), default_downsampler=LTTB(interleave_gaps=True))\n",
    "\n",
    "fig.add_trace(go.Scattergl(name=\"target\"), hf_x=y_test.index, hf_y=y_test)\n",
    "\n",
    "\n",
    "for name, pipe in [(\"MAPE\", mape_pipe), (\"RMSE\", rmse_pipe), (\"MAE\", mae_pipe)]:\n",
    "    test_predictions = pd.Series(\n",
    "        pipe.predict(test_feats), index=test_feats.index\n",
    "    ).rename(\"predictions\")\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(name=f\"predictions-{name}\"),\n",
    "        hf_x=test_predictions.index,\n",
    "        hf_y=test_predictions,\n",
    "    )\n",
    "\n",
    "fig.update_layout(title=\"Power consumption predictions\", title_x=0.5, height=600)\n",
    "fig.update_xaxes(title=\"Time\")\n",
    "fig.update_yaxes(title=\"AVG power consumption (kW)\")\n",
    "fig.show_dash(mode=\"external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33312237",
   "metadata": {},
   "source": [
    "## 4.6 Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "explainer = shap.TreeExplainer(pipe)\n",
    "shap_values = explainer.shap_values(df_train[selected_cols])\n",
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    df_train[selected_cols],\n",
    "    max_display=50,\n",
    "    auto_size_plot=True,\n",
    "    show=False,\n",
    "    color_bar=True,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.abs(shap_values).mean(0)\n",
    "feature_importance = pd.DataFrame(\n",
    "    list(zip(selected_cols, vals)), columns=[\"col_name\", \"feature_importance_vals\"]\n",
    ")\n",
    "feature_importance = feature_importance.sort_values(\n",
    "    by=[\"feature_importance_vals\"], ascending=False\n",
    ").reset_index(drop=True)\n",
    "feature_importance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf4bff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecd834c-8adc-4183-ad35-a5fd3406e358",
   "metadata": {},
   "source": [
    "## 4.6 Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1d536",
   "metadata": {},
   "source": [
    "For specific use-cases it is beneficial to add estimates of uncertainty to the prediction of your model. \n",
    "\n",
    "There are multiple ways of adding uncertainty to the output, depending whether the problem is a clasification or a regression problem. For a classification problem, the uncertainty estimates could be percentages assigned to each class, while for regression problems the uncertainty is either in the form of a distribution or a prediction interval. In our case, we will focus on a `regression prediction interval`.\n",
    "\n",
    "Uncertainty is a broad term, however, two different kinds of uncertainty can be differentiated: The **epistemic** or model uncertainty and the **aleotoric** or data uncertainty.<br>\n",
    "The aleotoric uncertainty is fully determined by the data and any uncertainty introduced by the current dataset. An example of the aleotoric uncertainty is a measurement error of a specific feature, e.g. the power consumption in our case. This measurement error cannot be reduced by any amount of data and is always present, hence, the aleotoric uncertainty is sometimes referred to as the irreducible uncertainty. Therefore, in any machine learning problem, the **theoretical maximum performance a model** can achieve is **bounded by** the **aleotoric uncertainty**.<br>\n",
    "The epistemic uncertainty on the other hand is reducible as it contains all uncertainty introduced by your model. There are multiple sources for the epistemic uncertainty but they are all traced back by the used and trained model: the used parameters, the model assumptions, the model error, etc. In uncertainty quantification the main goal is to quantify both uncertainties. \n",
    "\n",
    "In regression problems, a common way of introducing uncertainty is by creating `prediction intervals`. These intervals **specify a range that will contain the true ground truth value with a certain coverage percentage**. For example, if the prediction interval for a specific output is \\[8,20\\] with 95% coverage then this means that the true value lies in between 8 and 20 with 95% certainty. In other words, this means that in 95 cases of 100 predictions, the ground truth value will lie in between these two values. This therefore provides uncertainty in your prediction in the form of error bars. An extension of prediction intervals uses distributions, which directly provides prediction intervals for any possible coverage percentage. However, we will limit the scope to prediction intervals in this introductory section. \n",
    "\n",
    "There are multiple ways to predict prediction intervals, but the most easy way makes use of `quantile regression`. In regular regression you want to directly predict the label or output, while in quantile prediction you want to predict the quantile of the labels. A quantile is a threshold or value in a distribution of samples where a percentage **p** of all values are below or equal to that threshold-value. The median of any distribution is also equal to the 0.5 or 50% quantile, as 50% of all values are equal or lower to the median. The image below explains quantiles using a normal distribution.\n",
    "\n",
    "![image.png](https://cdn.discordapp.com/attachments/894288331309989978/920039657713053696/Image_Pasted_at_2021-12-13_20-00.jpeg)\n",
    "\n",
    "Therefore, if you have a quantile regressor that predict the 0.975 quantile it predicts a value for each data sample, such that for all predicted values the the label is below or equal to that value in 97,5% of the cases, i.e. having a coverage of 97,5%. This technique is useful for creating a prediction interval as a prediction interval also provides a coverage, but compared to a quantile, the prediction interval has an upper and a lower bound. Therefore, we will use two models: one for the lower and one for the upper bound of the prediction interval. If we want a symmetric prediction interval of 95% we need to have a lower bound of 2.5% and an upper bound of 97.5% (as 97.5% - 2.5% = 95%).\n",
    "\n",
    "In the following code, two CatBoostRegressors are trained but using a quantile-loss function (or pinball-loss function) where the coverage is defined by alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba558aeb-3d8d-43d5-81cc-50e951bd3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = catboost.CatBoostRegressor(verbose=250, loss_function=\"RMSE\")\n",
    "pipe_upper = catboost.CatBoostRegressor(\n",
    "    verbose=250, loss_function=\"Quantile:alpha=0.975\"\n",
    ")\n",
    "pipe_lower = catboost.CatBoostRegressor(\n",
    "    verbose=250, loss_function=\"Quantile:alpha=0.025\"\n",
    ")\n",
    "\n",
    "# as this is a lot of data, this might take a couple of minutes\n",
    "pipe.fit(df_train[selected_cols], df_train[y_train.name])\n",
    "pipe_upper.fit(df_train[selected_cols], df_train[y_train.name])\n",
    "pipe_lower.fit(df_train[selected_cols], df_train[y_train.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b86ee4",
   "metadata": {},
   "source": [
    "Evaluating a quantile model or a prediction interval cannot be done with standard metrics such as RMSE or R, as we do not have the true quantile labels. Therefore we will look back at the definition of a prediction interval: A prediction interval provides a range that will contain the true value in C % of the times, with C the coverage percentage. As a result, **to measure the performance of the prediction interval we can count how many times the label $y$ is in between the upper $y_U$ and lower bound $y_L$**. This is called the `Prediction Interval Coverage Percentage or PICP`:\n",
    "\n",
    "$PICP(y,y_L,y_U)=\\frac{1}{N} \\sum_{i=1}^N  I(y_i \\in [y_{L_i};y_{U_i}])$\n",
    "\n",
    "With I the indicator function, giving a 1 if the expression is true and 0 otherwise. \n",
    "\n",
    "The PICP is then a measure of coverage and is an important metric in regression uncertainty quantification. However, solemnly relying on the PICP is not a good idea. Consider the case where we have perfect coverage but the model outputs the same exact value for any data sample. This is possible by providing a prediction interval that is large enough to contain all values in the dataset. Although the coverage is perfect the prediction interval is actually useless as this interval is way too large and provides no real uncertainty estimate. Therefore, it is also necessary to **measure the width of the prediction interval in conjunction with the coverage** to have full understanding of the uncertainty quantification performance of your model. This can be done using the `(Normalized) Mean Prediction Interval Width or (N)MPIW` that calculates the **mean width of all prediction intervals**:\n",
    "\n",
    "$MPIW(y_L,y_U)=\\frac{1}{N} \\sum_{i=1}^N y_{U_i} - y_{U_i} $\n",
    "\n",
    "$NMPIW(y_L,y_U)=\\frac{MPIW(y_L,y_U)}{max(y)-min(y)} $\n",
    "\n",
    "The `goal` of all uncertainty quantification models is to **achieve prediction intervals that are as small as possible but have a perfect coverage**. However, this is a trade-off. In general, to achieve a higher coverage you have to widen the prediction intervals and therefore this is called the coverage-width trade-off. \n",
    "\n",
    "These three metrics are defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5693f62-5451-448d-a88e-1dad9dbb324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PICP(y_true, y_lower, y_upper):\n",
    "    # ratio of how many times the label y is between the upper and the lower bound\n",
    "    return (\n",
    "        np.logical_and(y_lower <= y_true, y_true <= y_upper).sum() / len(y_true) * 100\n",
    "    )\n",
    "\n",
    "\n",
    "def MPIW(y_lower, y_upper):\n",
    "    # \n",
    "    return np.mean(y_upper - y_lower)\n",
    "\n",
    "\n",
    "def NMPIW(y_true, y_lower, y_upper):\n",
    "    return MPIW(y_lower, y_upper) / (np.max(y_true) - np.min(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377f895-d8e2-4d96-a95c-90ce7fac67e9",
   "metadata": {},
   "source": [
    "Since we now have defined the metrics we can apply them to the predictions of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4ee43-c944-49e3-9dd3-c5b135970727",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_upper = pipe_upper.predict(df_train[selected_cols])\n",
    "train_predictions_lower = pipe_lower.predict(df_train[selected_cols])\n",
    "\n",
    "nan_mask = df_train[target_col].notna()\n",
    "y_true, y_pred_upper, y_pred_lower = (\n",
    "    df_train[target_col][nan_mask],\n",
    "    train_predictions_upper[nan_mask],\n",
    "    train_predictions_lower[nan_mask],\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"[TRAIN] PICP = \"\n",
    "    + str(np.round(PICP(y_true.values, y_pred_lower, y_pred_upper), 2))\n",
    "    + \" % -- NMPIW = \"\n",
    "    + str(np.round(NMPIW(y_true.values, y_pred_lower, y_pred_upper), 2))\n",
    "    + \" -- MPIW = \"\n",
    "    + str(np.round(MPIW(y_pred_lower, y_pred_upper), 2))\n",
    "    + \" kW\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da8132-8b63-4efd-8089-393f6618da3d",
   "metadata": {},
   "source": [
    "As you can see, the training performance has a perfect coverage as we achieved a PICP of 95% which was our specified uncertainty requirement. The average width is 2 kW of all prediction intervals which corresponds to 24% of the range of the labels. However, it is also necessary to do this evaluation on the test set to understand how well our uncertainty model can generalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acf5de-35f9-445d-a3db-40b267e52283",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feats[\"predictions_upper\"] = pipe_upper.predict(test_feats[selected_cols])\n",
    "test_feats[\"predictions_lower\"] = pipe_lower.predict(test_feats[selected_cols])\n",
    "\n",
    "test_feats_ = test_feats.join(y_test)\n",
    "nan_mask = test_feats_[target_col].notna()\n",
    "y_true, y_pred_upper, y_pred_lower = (\n",
    "    test_feats_[nan_mask][target_col],\n",
    "    test_feats_[nan_mask][\"predictions_upper\"],\n",
    "    test_feats_[nan_mask][\"predictions_lower\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"[TEST] PICP = \"\n",
    "    + str(np.round(PICP(y_true.values, y_pred_lower.values, y_pred_upper.values), 2))\n",
    "    + \" % -- NMPIW = \"\n",
    "    + str(np.round(NMPIW(y_true.values, y_pred_lower.values, y_pred_upper.values), 2))\n",
    "    + \" -- MPIW = \"\n",
    "    + str(np.round(MPIW(y_pred_lower.values, y_pred_upper.values), 2))\n",
    "    + \" kW\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee8832-132d-4614-bd01-747b9136d579",
   "metadata": {},
   "source": [
    "The coverage is a bit higher, but it is better to have a higher coverage then specified compared to a lower coverage to avoid missing crucial data. Compared to the training set, the width is slightly smaller in absolute values. In order to understand the prediction interval more, we can plot the width to the most important feature: 'Global_intensity__amin__w=15m_s=15m'. This way we can see what kind of relationship there is and how the width varies across the data. If the width is the same for any feature, then we have a homoscedastic solution, i.e. the error bars are approximately the same for every data sample. In the other case, with a varying width, we have a heteroscedastic solution. The heteroscedastic solution is often preferred as this provides more individualized prediction for the data sample instead of a more general solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72480397-a67f-41be-a2f4-180fdd9c77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(\n",
    "    df_train[\"Global_active_power__amin__w=15m_s=15m\"],\n",
    "    train_predictions_upper - train_predictions_lower,\n",
    ")\n",
    "plt.xlabel(\"Global_intensity__amin__w=15m_s=15m\")\n",
    "plt.ylabel(\"Width prediction interval (kW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b687bb-b68c-41e8-b9cf-be21bef33076",
   "metadata": {},
   "source": [
    "In the figure above, we can see that the width increases on average with the global intensity. Therefore, we can conclude that we have a heteroscedastic solution which can be used in practice together with good PICP and NMPIW metrics for the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03855696",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88161a53-e122-4a33-b80a-e086c9222d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = FigureResampler(\n",
    "    make_subplots(rows=2, shared_xaxes=True, specs=[[{}], [{\"secondary_y\": True}]]),\n",
    "    default_n_shown_samples=1000,\n",
    "    default_downsampler=LTTB(interleave_gaps=True),\n",
    ")\n",
    "\n",
    "test_predictions = pd.Series(\n",
    "    pipe.predict(test_feats[selected_cols]), index=test_feats.index\n",
    ").rename(\"predictions\")\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scattergl(name=\"target\"), hf_x=y_test.index, hf_y=y_test, row=1, col=1)\n",
    "\n",
    "df_pc_test = df_power_consumption[y_test.index[0]: y_test.index[-1]]\n",
    "fig.add_trace(\n",
    "    go.Scattergl(name=\"REAL - GAP\", visible=\"legendonly\"),\n",
    "    hf_x=df_pc_test.index,\n",
    "    hf_y=df_pc_test[\"Global_active_power\"],\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattergl(name=\"predictions\", marker_color=\"red\"),\n",
    "    hf_x=test_predictions.index,\n",
    "    hf_y=test_predictions,\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test_feats.index,\n",
    "        y=test_feats.predictions_upper,\n",
    "        name=\"upper_bound\",\n",
    "        showlegend=False,\n",
    "        marker_color=\"black\",\n",
    "        line=dict(width=0),\n",
    "        mode=\"lines\",\n",
    "    ),\n",
    "    downsampler=EveryNthPoint(),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test_feats.index,\n",
    "        y=test_feats.predictions_lower,\n",
    "        name=\"lower bound\",\n",
    "        showlegend=False,\n",
    "        marker_color=\"black\",\n",
    "        line=dict(width=0),\n",
    "        mode=\"lines\",\n",
    "        fillcolor=\"rgba(255, 0, 0, 0.2)\",\n",
    "        fill=\"tonexty\",\n",
    "    ),\n",
    "    downsampler=EveryNthPoint(),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scattergl(name=\"MAE\"),\n",
    "    row=2,\n",
    "    col=1,\n",
    "    hf_x=test_predictions.index,\n",
    "    hf_y=abs(test_predictions - test_predictions.to_frame().join(y_test).iloc[:, -1]),\n",
    ")\n",
    "\n",
    "fig.update_layout(title=\"Power consumption predictions\", title_x=0.5, height=700)\n",
    "fig.update_xaxes(title=\"Time\")\n",
    "fig.update_yaxes(title=\"AVG power consumption (kW)\")\n",
    "fig.show_dash(mode=\"external\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302690ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df43788",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5. Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2d981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_dump(obj, file_name):\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the feature extraction logic\n",
    "fc.serialize(\"fc.pkl\")\n",
    "sp.serialize(\"sp.pkl\")\n",
    "\n",
    "# serialize the pipeline\n",
    "pickle_dump(selected_cols, \"cols.pkl\")\n",
    "pickle_dump(pipe, \"pipe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7a9e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfeb4fb-00f1-4ccb-bacb-500fc50dee67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 6. Some notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef77ea-5641-4b5e-8838-3972c69e8e23",
   "metadata": {},
   "source": [
    "This notebook is far from complete and serves as \"quick\" first iteration\n",
    "\n",
    "Ideally one would tackle this approach using the [cookiecutter-data science](https://drivendata.github.io/cookiecutter-data-science/) structure (see demo)\n",
    "\n",
    "Some steps which I would further pursue:\n",
    "* Compute some more advanced signal features (peaks)\n",
    "* There is an underlying pattern - so maybe shapelets?\n",
    "* using a linear model as baseline\n",
    "* trying other windows / strides\n",
    "* as you keep getting new data (client want to use it for forecasting); incremental learning models might be a better suit for this use-case"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "058975938d2190a16515f75fca60e764787758da52be5bbf3c711d7cb37de623"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
